{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Header</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Imports</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import sinogap_module as sg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Redefine</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.plt.rcParams['figure.dpi']=223\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Configs</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.set_seed(7)\n",
    "\n",
    "sg.TCfg = sg.TCfgClass(\n",
    "     exec = 2\n",
    "    ,nofEpochs = None\n",
    "    ,latentDim = 64\n",
    "    ,batchSize = 128    #16384 #32768\n",
    "    ,labelSmoothFac = 0.1 # For Fake labels (or set to 0.0 for no smoothing).\n",
    "    ,learningRateD = 0.0002\n",
    "    ,learningRateG = 0.0002\n",
    ")\n",
    "\n",
    "sg.DCfg = sg.DCfgClass(16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Raw Read</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded set 23574.8965435L.Eiger.32kev_org\n"
     ]
    }
   ],
   "source": [
    "trainSet = sg.createTrainSet()\n",
    "prepGdLoss=0\n",
    "testSet = sg.createTestSet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Show</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.refImages, sg.refNoises = sg.createReferences(trainSet, 0)\n",
    "sg.showMe(trainSet, 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "source": [
    "## <font style=\"color:lightblue\">Models</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator 2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Generator2(sg.GeneratorTemplate):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator2, self).__init__(2)\n",
    "\n",
    "        #latentChannels = 7\n",
    "        #self.noise2latent = nn.Sequential(\n",
    "        #    nn.Linear(sg.TCfg.latentDim, self.sinoSize*latentChannels),\n",
    "        #    nn.ReLU(),\n",
    "        #    nn.Unflatten( 1, (latentChannels,) + self.sinoSh )\n",
    "        #)\n",
    "\n",
    "        baseChannels = 64\n",
    "\n",
    "        self.encoders =  nn.ModuleList([\n",
    "            self.encblock(  1,                baseChannels, 3, norm=False),\n",
    "            self.encblock(  baseChannels,     baseChannels, 3),\n",
    "            self.encblock(  baseChannels,     baseChannels, 3),\n",
    "            ])\n",
    "\n",
    "        smpl = torch.zeros((1,1,*self.sinoSh))\n",
    "        for encoder in self.encoders :\n",
    "            smpl = encoder(smpl)\n",
    "        encSh = smpl.shape\n",
    "        linChannels = math.prod(encSh)\n",
    "        self.fcLink = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(linChannels, linChannels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(linChannels, linChannels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Unflatten(1, encSh[1:]),\n",
    "        )\n",
    "        sg.fillWheights(self.fcLink)\n",
    "\n",
    "        self.decoders = nn.ModuleList([\n",
    "            self.decblock(2*baseChannels, baseChannels, 3),\n",
    "            self.decblock(2*baseChannels, baseChannels, 3),\n",
    "            self.decblock(2*baseChannels, baseChannels, 3, norm=False),\n",
    "            ])\n",
    "\n",
    "        self.lastTouch = nn.Sequential(\n",
    "            nn.Conv2d(baseChannels+1, 1, 1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        sg.fillWheights(self.lastTouch)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        images, _ = input\n",
    "        images, orgDims = sg.unsqeeze4dim(images)\n",
    "        modelIn = images.clone()\n",
    "        modelIn[self.gapRng] = self.preProc(images)\n",
    "\n",
    "        minv = modelIn.min(dim=-1).values.min(dim=-1).values\n",
    "        ampl = modelIn.max(dim=-1).values.max(dim=-1).values - minv\n",
    "        minv = minv[:,:,None,None]\n",
    "        ampl = ampl[:,:,None,None]\n",
    "        iampl = torch.where(ampl==0, 0, 2/ampl)\n",
    "        modelIn = ( modelIn - minv ) * iampl - 1 # stretch\n",
    "\n",
    "        #latent = self.noise2latent(noises)\n",
    "        #modelIn = torch.cat((modelIn,latent),dim=1).to(sg.TCfg.device)\n",
    "        dwTrain = [modelIn,]\n",
    "        for encoder in self.encoders :\n",
    "            dwTrain.append(encoder(dwTrain[-1]))\n",
    "        mid = self.fcLink(dwTrain[-1])\n",
    "        upTrain = [mid]\n",
    "        for level, decoder in enumerate(self.decoders) :\n",
    "            upTrain.append( decoder( torch.cat( (upTrain[-1], dwTrain[-1-level]), dim=1 ) ) )\n",
    "        res = self.lastTouch(torch.cat( (upTrain[-1], modelIn), dim=1 ))\n",
    "\n",
    "        patches = ( 2*res[self.gapRng] + modelIn[:,[0],:, self.gapRngX] + 1 ) * ampl / 2 + minv #destretch\n",
    "        return sg.squeezeOrg(patches, orgDims)\n",
    "\n",
    "\n",
    "\n",
    "generator2 = Generator2()\n",
    "generator2 = sg.load_model(generator2, model_path=\"saves/gen2.pt\" )\n",
    "generator2 = generator2.to(sg.TCfg.device)\n",
    "generator2 = generator2.requires_grad_(False)\n",
    "generator2 = generator2.eval()\n",
    "sg.lowResGenerators[2] = generator2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator 4pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Generator4(sg.GeneratorTemplate):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator4, self).__init__(4)\n",
    "\n",
    "        #latentChannels = 7\n",
    "        #self.noise2latent = nn.Sequential(\n",
    "        #    nn.Linear(sg.TCfg.latentDim, self.sinoSize*latentChannels),\n",
    "        #    nn.ReLU(),\n",
    "        #    nn.Unflatten( 1, (latentChannels,) + self.sinoSh )\n",
    "        #)\n",
    "\n",
    "        baseChannels = 64\n",
    "\n",
    "\n",
    "        self.encoders =  nn.ModuleList([\n",
    "            self.encblock(  1,                  baseChannels, 3, norm=False),\n",
    "            self.encblock(  baseChannels,       baseChannels, 3),\n",
    "            self.encblock(  baseChannels,     2*baseChannels, 3, stride=2),\n",
    "            self.encblock(  2*baseChannels,   2*baseChannels, 3),\n",
    "            self.encblock(  2*baseChannels,   4*baseChannels, 3),\n",
    "            ])\n",
    "\n",
    "        smpl = torch.zeros((1,1,*self.sinoSh))\n",
    "        for encoder in self.encoders :\n",
    "            smpl = encoder(smpl)\n",
    "        encSh = smpl.shape\n",
    "        linChannels = math.prod(encSh)\n",
    "        self.fcLink = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(linChannels, linChannels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(linChannels, linChannels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Unflatten(1, encSh[1:]),\n",
    "        )\n",
    "        sg.fillWheights(self.fcLink)\n",
    "\n",
    "        self.decoders = nn.ModuleList([\n",
    "            self.decblock(8*baseChannels, 2*baseChannels, 3),\n",
    "            self.decblock(4*baseChannels, 2*baseChannels, 3),\n",
    "            self.decblock(4*baseChannels,   baseChannels, 4, stride=2),\n",
    "            self.decblock(2*baseChannels,   baseChannels, 3),\n",
    "            self.decblock(2*baseChannels,   baseChannels, 3, norm=False),\n",
    "            ])\n",
    "\n",
    "        self.lastTouch = nn.Sequential(\n",
    "            nn.Conv2d(baseChannels+1, 1, 1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        sg.fillWheights(self.lastTouch)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        images, noises = input\n",
    "        images, orgDims = sg.unsqeeze4dim(images)\n",
    "        modelIn = images.clone()\n",
    "        modelIn[self.gapRng] = self.preProc(images)\n",
    "\n",
    "        #latent = self.noise2latent(noises)\n",
    "        #modelIn = torch.cat((modelIn,latent),dim=1).to(sg.TCfg.device)\n",
    "        dwTrain = [modelIn,]\n",
    "        for encoder in self.encoders :\n",
    "            dwTrain.append(encoder(dwTrain[-1]))\n",
    "        mid = self.fcLink(dwTrain[-1])\n",
    "        upTrain = [mid]\n",
    "        for level, decoder in enumerate(self.decoders) :\n",
    "            upTrain.append( decoder( torch.cat( (upTrain[-1], dwTrain[-1-level]), dim=1 ) ) )\n",
    "        res = self.lastTouch(torch.cat( (upTrain[-1], modelIn ), dim=1 ))\n",
    "\n",
    "        patches = modelIn[self.gapRng] + 2 * res[self.gapRng]\n",
    "        return sg.squeezeOrg(patches, orgDims)\n",
    "\n",
    "generator4 = Generator4()\n",
    "generator4 = sg.load_model(generator4, model_path=\"saves/gen4.pt\" )\n",
    "generator4 = generator4.to(sg.TCfg.device)\n",
    "generator4 = generator4.requires_grad_(False)\n",
    "generator4 = generator4.eval()\n",
    "sg.lowResGenerators[4] = generator4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator 8pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Generator8(sg.GeneratorTemplate):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator8, self).__init__(8)\n",
    "\n",
    "        #latentChannels = 7\n",
    "        #self.noise2latent = nn.Sequential(\n",
    "        #    nn.Linear(sg.TCfg.latentDim, self.sinoSize*latentChannels),\n",
    "        #    nn.ReLU(),\n",
    "        #    nn.Unflatten( 1, (latentChannels,) + self.sinoSh )\n",
    "        #)\n",
    "\n",
    "        baseChannels = 64\n",
    "\n",
    "        self.encoders =  nn.ModuleList([\n",
    "            self.encblock( 1,                  baseChannels, 3, norm=False),\n",
    "            self.encblock( baseChannels,       baseChannels, 3, dopadding=True),\n",
    "            self.encblock( baseChannels,     2*baseChannels, 3, stride=2),\n",
    "            self.encblock( 2*baseChannels,   2*baseChannels, 3, dopadding=True),\n",
    "            self.encblock( 2*baseChannels,   4*baseChannels, 3, stride=2),\n",
    "            self.encblock( 4*baseChannels,   4*baseChannels, 3, dopadding=True),\n",
    "            self.encblock( 4*baseChannels,   8*baseChannels, 3, stride=2),\n",
    "            self.encblock( 8*baseChannels,   8*baseChannels, 3, dopadding=True),\n",
    "            ])\n",
    "\n",
    "        smpl = torch.zeros((1,1,*self.sinoSh))\n",
    "        for encoder in self.encoders :\n",
    "            smpl = encoder(smpl)\n",
    "        encSh = smpl.shape\n",
    "        linChannels = math.prod(encSh)\n",
    "        self.fcLink = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(linChannels, linChannels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(linChannels, linChannels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Unflatten(1, encSh[1:]),\n",
    "        )\n",
    "        sg.fillWheights(self.fcLink)\n",
    "\n",
    "        self.decoders = nn.ModuleList([\n",
    "            self.decblock(16*baseChannels, 8*baseChannels, 3, dopadding=True),\n",
    "            self.decblock(16*baseChannels, 4*baseChannels, 4, stride=2),\n",
    "            self.decblock( 8*baseChannels, 4*baseChannels, 3, dopadding=True),\n",
    "            self.decblock( 8*baseChannels, 2*baseChannels, 4, stride=2),\n",
    "            self.decblock( 4*baseChannels, 2*baseChannels, 3, dopadding=True),\n",
    "            self.decblock( 4*baseChannels,   baseChannels, 4, stride=2),\n",
    "            self.decblock( 2*baseChannels,   baseChannels, 3, dopadding=True),\n",
    "            self.decblock( 2*baseChannels,   baseChannels, 3, norm=False),\n",
    "            ])\n",
    "\n",
    "        self.lastTouch = nn.Sequential(\n",
    "            nn.Conv2d(baseChannels+1, 1, 1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        sg.fillWheights(self.lastTouch)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        images, noises = input\n",
    "        images, orgDims = sg.unsqeeze4dim(images)\n",
    "        modelIn = images.clone()\n",
    "        modelIn[self.gapRng] = self.preProc(images)\n",
    "\n",
    "        #latent = self.noise2latent(noises)\n",
    "        #modelIn = torch.cat((modelIn,latent),dim=1).to(sg.TCfg.device)\n",
    "        dwTrain = [modelIn,]\n",
    "        for encoder in self.encoders :\n",
    "            dwTrain.append(encoder(dwTrain[-1]))\n",
    "        mid = self.fcLink(dwTrain[-1])\n",
    "        #return mid\n",
    "        upTrain = [mid]\n",
    "        for level, decoder in enumerate(self.decoders) :\n",
    "            upTrain.append( decoder( torch.cat( (upTrain[-1], dwTrain[-1-level]), dim=1 ) ) )\n",
    "        res = self.lastTouch(torch.cat( (upTrain[-1], modelIn ), dim=1 ))\n",
    "\n",
    "        patches = modelIn[self.gapRng] + 2 * res[self.gapRng]\n",
    "        return sg.squeezeOrg(patches, orgDims)\n",
    "\n",
    "generator8 = Generator8()\n",
    "generator8 = sg.load_model(generator8, model_path=\"saves/gen8.pt\" )\n",
    "generator8 = generator8.to(sg.TCfg.device)\n",
    "generator8 = generator8.requires_grad_(False)\n",
    "generator8 = generator8.eval()\n",
    "sg.lowResGenerators[8] = generator8\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Generator</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Generator16(sg.GeneratorTemplate):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator16, self).__init__(16)\n",
    "\n",
    "        #latentChannels = 7\n",
    "        #self.noise2latent = nn.Sequential(\n",
    "        #    nn.Linear(sg.TCfg.latentDim, self.sinoSize*latentChannels),\n",
    "        #    nn.ReLU(),\n",
    "        #    nn.Unflatten( 1, (latentChannels,) + self.sinoSh )\n",
    "        #)\n",
    "\n",
    "        baseChannels = 64\n",
    "\n",
    "        self.encoders =  nn.ModuleList([\n",
    "            self.encblock( 1,                  baseChannels, 3, norm=False),\n",
    "            self.encblock( baseChannels,       baseChannels, 3, dopadding=True),\n",
    "            self.encblock( baseChannels,     2*baseChannels, 3, stride=2),\n",
    "            self.encblock( 2*baseChannels,   2*baseChannels, 3, dopadding=True),\n",
    "            self.encblock( 2*baseChannels,   4*baseChannels, 3, stride=2),\n",
    "            self.encblock( 4*baseChannels,   4*baseChannels, 3, dopadding=True),\n",
    "            self.encblock( 4*baseChannels,   8*baseChannels, 3, stride=2),\n",
    "            self.encblock( 8*baseChannels,   8*baseChannels, 3, dopadding=True),\n",
    "            self.encblock( 8*baseChannels,  16*baseChannels, 3, stride=2),\n",
    "            self.encblock(16*baseChannels,  16*baseChannels, 3, dopadding=True),\n",
    "            ])\n",
    "\n",
    "        smpl = torch.zeros((1,1,*self.sinoSh))\n",
    "        for encoder in self.encoders :\n",
    "            smpl = encoder(smpl)\n",
    "        encSh = smpl.shape\n",
    "        linChannels = math.prod(encSh)\n",
    "        self.fcLink = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(linChannels, linChannels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(linChannels, linChannels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Unflatten(1, encSh[1:]),\n",
    "        )\n",
    "        sg.fillWheights(self.fcLink)\n",
    "\n",
    "        self.decoders = nn.ModuleList([\n",
    "            self.decblock(32*baseChannels,16*baseChannels, 3, dopadding=True),\n",
    "            self.decblock(32*baseChannels, 8*baseChannels, 4, stride=2),\n",
    "            self.decblock(16*baseChannels, 8*baseChannels, 3, dopadding=True),\n",
    "            self.decblock(16*baseChannels, 4*baseChannels, 4, stride=2),\n",
    "            self.decblock( 8*baseChannels, 4*baseChannels, 3, dopadding=True),\n",
    "            self.decblock( 8*baseChannels, 2*baseChannels, 4, stride=2),\n",
    "            self.decblock( 4*baseChannels, 2*baseChannels, 3, dopadding=True),\n",
    "            self.decblock( 4*baseChannels,   baseChannels, 4, stride=2),\n",
    "            self.decblock( 2*baseChannels,   baseChannels, 3, dopadding=True),\n",
    "            self.decblock( 2*baseChannels,   baseChannels, 3, norm=False),\n",
    "            ])\n",
    "\n",
    "        self.lastTouch = nn.Sequential(\n",
    "            nn.Conv2d(baseChannels+1, 1, 1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        sg.fillWheights(self.lastTouch)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        images, noises = input\n",
    "        images, orgDims = sg.unsqeeze4dim(images)\n",
    "        modelIn = images.clone()\n",
    "        modelIn[self.gapRng] = self.preProc(images)\n",
    "\n",
    "        #latent = self.noise2latent(noises)\n",
    "        #modelIn = torch.cat((modelIn,latent),dim=1).to(sg.TCfg.device)\n",
    "        dwTrain = [modelIn,]\n",
    "        for encoder in self.encoders :\n",
    "            dwTrain.append(encoder(dwTrain[-1]))\n",
    "        mid = self.fcLink(dwTrain[-1])\n",
    "        #return mid\n",
    "        upTrain = [mid]\n",
    "        for level, decoder in enumerate(self.decoders) :\n",
    "            upTrain.append( decoder( torch.cat( (upTrain[-1], dwTrain[-1-level]), dim=1 ) ) )\n",
    "        res = self.lastTouch(torch.cat( (upTrain[-1], modelIn ), dim=1 ))\n",
    "\n",
    "        patches = modelIn[self.gapRng] + 2 * res[self.gapRng]\n",
    "        return sg.squeezeOrg(patches, orgDims)\n",
    "\n",
    "sg.generator = Generator16()\n",
    "sg.generator.to(sg.TCfg.device)\n",
    "model_summary = summary(sg.generator, input_data=[ [sg.refImages[[0],...], sg.refNoises[[0],...]] ] ).__str__()\n",
    "print(model_summary)\n",
    "\n",
    "sg.optimizer_G = sg.createOptimizer(sg.generator, sg.TCfg.learningRateG)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Discriminator</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Discriminator(sg.DiscriminatorTemplate):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.param = nn.Parameter(torch.zeros(1))\n",
    "    def forward(self, images):\n",
    "        return torch.zeros((images.shape[0],1), device=sg.TCfg.device)\n",
    "\n",
    "\n",
    "sg.discriminator = Discriminator()\n",
    "sg.discriminator = sg.discriminator.to(sg.TCfg.device)\n",
    "model_summary = summary(sg.discriminator, input_data=sg.refImages[0,...] ).__str__()\n",
    "#print(model_summary)\n",
    "#sg.writer.add_graph(sg.discriminator, refImages)\n",
    "\n",
    "sg.optimizer_D = sg.createOptimizer(sg.discriminator, sg.TCfg.learningRateD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Optimizers</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sg.optimizer_G , sg.optimizer_D = sg.createOptimizers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Restore checkpoint</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedCheckPoint = f\"checkPoint_{sg.TCfg.exec}\"\n",
    "sg.epoch, sg.iter, sg.minGEpoch, sg.minGdLoss = sg.restoreCheckpoint(savedCheckPoint+\".pth\")\n",
    "sg.writer = sg.createWriter(sg.TCfg.logDir, True)\n",
    "#sg.writer.add_graph(sg.generator, ((sg.refImages, sg.refNoises),) )\n",
    "#sg.writer.add_graph(sg.discriminator, refImages)\n",
    "sg.initialTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Execute</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#sg.TCfg.batchSize = 128\n",
    "sg.dataLoader = sg.createTrainLoader(trainSet, num_workers=8)\n",
    "sg.testLoader = sg.createTestLoader(testSet, num_workers=8)\n",
    "#Rec_diff, MSE_diff, L1L_diff = sg.summarizeSet(sg.testLoader)\n",
    "##Summary. Rec: 2.203e-03, MSE: 2.203e-03, L1L: 1.882e-02.\n",
    "#sg.writer.add_scalars(\"Test per epoch\",\n",
    "#                   {'MSE': MSE_diff\n",
    "#                   ,'L1L': L1L_diff\n",
    "#                   ,'REC': Rec_diff\n",
    "#                   }, 0 )\n",
    "#Rec_diff, MSE_diff, L1L_diff = sg.summarizeSet(sg.testLoader, False)\n",
    "##Summary. Rec: 2.190e-03, MSE: 2.190e-03, L1L: 1.854e-02\n",
    "#sg.writer.add_scalars(\"Test per epoch\",\n",
    "#                   {'MSE': MSE_diff\n",
    "#                   ,'L1L': L1L_diff\n",
    "#                   ,'REC': Rec_diff\n",
    "#                   }, sg.epoch )\n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "#Summary. Rec: 2.711e-03, MSE: 2.711e-03, L1L: 3.165e-02.\n",
    "Rec_diff, MSE_diff, L1L_diff = 2.711e-03, 2.711e-03, 3.165e-02\n",
    "sg.prepGdLoss =  Rec_diff\n",
    "if Rec_diff == 0:\n",
    "    Rec_diff, MSE_diff, L1L_diff = sg.summarizeSet(sg.dataLoader)\n",
    "if not sg.epoch :\n",
    "    sg.writer.add_scalars(\"Distances per epoch\",\n",
    "                          {'MSE': MSE_diff\n",
    "                          ,'L1L': L1L_diff\n",
    "                          ,'REC': Rec_diff\n",
    "                          }, 0 )\n",
    "\n",
    "#minGdLossToKeep = sg.minGdLoss\n",
    "#startingEpoch=sg.epoch\n",
    "#def my_afterEachEpoch(epoch) :\n",
    "#    global startingEpoch, minGdLossToKeep\n",
    "#    if sg.minGEpoch < startingEpoch+2 and sg.minGdLoss < minGdLossToKeep :\n",
    "#        sg.minGdLoss = minGdLossToKeep\n",
    "#        return\n",
    "#    for item in itertools.chain( sg.optimizer_D.param_groups, sg.optimizer_G.param_groups ):\n",
    "#        item['lr'] *= 0.99\n",
    "#sg.afterEachEpoch = my_afterEachEpoch\n",
    "\n",
    "#\n",
    "#def my_afterEachEpoch(epoch) :\n",
    "#    if sg.minGEpoch < 600 :\n",
    "#        return\n",
    "#    if not sg.dataLoader is None :\n",
    "#        del sg.dataLoader\n",
    "#        sg.freeGPUmem()\n",
    "#    if sg.TCfg.batchSize < 131072 :\n",
    "#    sg.TCfg.batchSize += round( 0.01 * sg.TCfg.batchSize )\n",
    "#    sg.dataLoader = sg.createTrainLoader(trainSet, num_workers=24)\n",
    "#    print(\"Batch size: \",sg.TCfg.batchSize)\n",
    "#sg.afterEachEpoch = my_afterEachEpoch\n",
    "\n",
    "sg.noAdv = True\n",
    "\n",
    "try :\n",
    "    sg.train(savedCheckPoint)\n",
    "except :\n",
    "    del sg.dataLoader\n",
    "    sg.freeGPUmem()\n",
    "    1/10 # to release Jupyuter memory in the next step\n",
    "    raise\n",
    "\n",
    "\n",
    " # purely diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Post</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.initialTest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.testMe(trainSet, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Save results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.saveModels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
