{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">Header</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fn\n",
    "from torch import optim\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread, imsave\n",
    "import h5py\n",
    "import tifffile\n",
    "\n",
    "def eprint(*args, **kwargs):\n",
    "    print(*args, file=sys.stderr, **kwargs)\n",
    "\n",
    "\n",
    "def plotData(dataY, rangeY=None, dataYR=None, rangeYR=None,\n",
    "             dataX=None, rangeX=None, rangeP=None,\n",
    "             figsize=(16,8), saveTo=None, show=True):\n",
    "\n",
    "    if type(dataY) is np.ndarray :\n",
    "        plotData((dataY,), rangeY=rangeY, dataYR=dataYR, rangeYR=rangeYR,\n",
    "             dataX=dataX, rangeX=rangeX, rangeP=rangeP,\n",
    "             figsize=figsize, saveTo=saveTo, show=show)\n",
    "        return\n",
    "    if type(dataYR) is np.ndarray :\n",
    "        plotData(dataY, rangeY=rangeY, dataYR=(dataYR,), rangeYR=rangeYR,\n",
    "             dataX=dataX, rangeX=rangeX, rangeP=rangeP,\n",
    "             figsize=figsize, saveTo=saveTo, show=show)\n",
    "        return\n",
    "    if type(dataY) is not tuple :\n",
    "        eprint(f\"Unknown data type to plot: {type(dataY)}.\")\n",
    "        return\n",
    "    if type(dataYR) is not tuple and dataYR is not None:\n",
    "        eprint(f\"Unknown data type to plot: {type(dataYR)}.\")\n",
    "        return\n",
    "\n",
    "    last = min( len(data) for data in dataY )\n",
    "    if dataYR is not None:\n",
    "        last = min( last,  min( len(data) for data in dataYR ) )\n",
    "    if dataX is not None:\n",
    "        last = min(last, len(dataX))\n",
    "    if rangeP is None :\n",
    "        rangeP = (0,last)\n",
    "    elif type(rangeP) is int :\n",
    "        rangeP = (0,rangeP) if rangeP > 0 else (-rangeP,last)\n",
    "    elif type(rangeP) is tuple :\n",
    "        rangeP = ( 0    if rangeP[0] is None else rangeP[0],\n",
    "                   last if rangeP[1] is None else rangeP[1],)\n",
    "    else :\n",
    "        eprint(f\"Bad data type on plotData input rangeP: {type(rangeP)}\")\n",
    "        raise Exception(f\"Bug in the code.\")\n",
    "    rangeP = np.s_[ max(0, rangeP[0]) : min(last, rangeP[1]) ]\n",
    "    if dataX is None :\n",
    "        dataX = np.arange(rangeP.start, rangeP.stop)\n",
    "\n",
    "    plt.style.use('default')\n",
    "    plt.style.use('dark_background')\n",
    "    fig, ax1 = plt.subplots(figsize=figsize)\n",
    "    ax1.xaxis.grid(True, 'both', linestyle='dotted')\n",
    "    if rangeX is not None :\n",
    "        ax1.set_xlim(rangeX)\n",
    "    else :\n",
    "        ax1.set_xlim(rangeP.start,rangeP.stop-1)\n",
    "\n",
    "    ax1.yaxis.grid(True, 'both', linestyle='dotted')\n",
    "    nofPlots = len(dataY)\n",
    "    if rangeY is not None:\n",
    "        ax1.set_ylim(rangeY)\n",
    "    colors = [ matplotlib.colors.hsv_to_rgb((hv/nofPlots, 1, 1)) for hv in range(nofPlots) ]\n",
    "    for idx , data in enumerate(dataY):\n",
    "        ax1.plot(dataX, data[rangeP], linestyle='-',  color=colors[idx])\n",
    "\n",
    "    if dataYR is not None : # right Y axis\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.yaxis.grid(True, 'both', linestyle='dotted')\n",
    "        nofPlots = len(dataYR)\n",
    "        if rangeYR is not None:\n",
    "            ax2.set_ylim(rangeYR)\n",
    "        colors = [ matplotlib.colors.hsv_to_rgb((hv/nofPlots, 1, 1)) for hv in range(nofPlots) ]\n",
    "        for idx , data in enumerate(dataYR):\n",
    "            ax2.plot(dataX, data[rangeP], linestyle='dashed',  color=colors[idx])\n",
    "\n",
    "    if saveTo:\n",
    "        fig.savefig(saveTo)\n",
    "    if not show:\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">Configs</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(SEED_VALUE):\n",
    "    torch.manual_seed(SEED_VALUE)\n",
    "    torch.cuda.manual_seed(SEED_VALUE)\n",
    "    torch.cuda.manual_seed_all(SEED_VALUE)\n",
    "    np.random.seed(SEED_VALUE)\n",
    "\n",
    "seed = 7\n",
    "set_seed(seed)\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    device: torch.device = 'cuda:0'\n",
    "    nofEpochs: int = 256\n",
    "    latentDim: int = 128\n",
    "    batchSize: int = 16\n",
    "    labelSmoothFac: float = 0.9 # For Real labels (or set to 1.0 for no smoothing).\n",
    "    learningRateD: float = 0.0002\n",
    "    learningRateG: float = 0.0002\n",
    "    #CHECKPOINT_DIR: str = os.path.join('model_checkpoint', 'dcgan_flickr_faces')\n",
    "\n",
    "class DatasetConfig:\n",
    "    gapWidth = 12\n",
    "    sinoWid = 3*gapWidth\n",
    "    sinoLen = 4096\n",
    "    gapSize = gapWidth * sinoLen\n",
    "    sinoSize = sinoWid * sinoLen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StripesFromHDF :\n",
    "\n",
    "    def __init__(self, sampleName, maskName, bgName=None, dfName=None, loadToMem=True):\n",
    "\n",
    "        sampleHDF = sampleName.split(':')\n",
    "        if len(sampleHDF) != 2 :\n",
    "            raise Exception(f\"String \\\"{sampleName}\\\" does not represent an HDF5 format.\")\n",
    "        with h5py.File(sampleHDF[0],'r') as trgH5F:\n",
    "            if  sampleHDF[1] not in trgH5F.keys():\n",
    "                raise Exception(f\"No dataset '{sampleHDF[1]}' in input file {sampleHDF[0]}.\")\n",
    "            self.data = trgH5F[sampleHDF[1]]\n",
    "            if not self.data.size :\n",
    "                raise Exception(f\"Container \\\"{sampleName}\\\" is zero size.\")\n",
    "            self.sh = self.data.shape\n",
    "            if len(self.sh) != 3 :\n",
    "                raise Exception(f\"Dimensions of the container \\\"{sampleName}\\\" is not 3 {self.sh}.\")\n",
    "            self.fsh = self.sh[1:3]\n",
    "            self.volume = None\n",
    "            if loadToMem :\n",
    "                self.volume = np.empty(self.sh, dtype=np.float32)\n",
    "                self.data.read_direct(self.volume)\n",
    "                trgH5F.close()\n",
    "\n",
    "            def loadImage(imageName) :\n",
    "                if not imageName:\n",
    "                    return None\n",
    "                imdata = imread(imageName).astype(np.float32)\n",
    "                if len(imdata.shape) == 3 :\n",
    "                    imdata = np.mean(imdata[:,:,0:3], 2)\n",
    "                #imdata = imdata.transpose()\n",
    "                if imdata.shape != self.fsh :\n",
    "                    raise Exception(f\"Dimensions of the input image \\\"{imageName}\\\" {imdata.shape} \"\n",
    "                                    f\"do not match the face of the container \\\"{sampleName}\\\" {self.fsh}.\")\n",
    "                return imdata\n",
    "\n",
    "\n",
    "            self.mask = loadImage(maskName)\n",
    "            if self.mask is None :\n",
    "                self.mask = np.ones(self.fsh, dtype=np.uint8)\n",
    "            self.mask = self.mask.astype(bool)\n",
    "            self.bg = loadImage(bgName)\n",
    "            self.df = loadImage(dfName)\n",
    "            if self.bg is not None :\n",
    "                if self.df is not None:\n",
    "                    self.bg -= self.df\n",
    "                self.mask  &=  self.bg > 0.0\n",
    "\n",
    "            self.allIndices = []\n",
    "            for yCr in range(0,self.fsh[0]) :\n",
    "                for xCr in range(0,self.fsh[1]) :\n",
    "                    idx = np.s_[yCr,xCr]\n",
    "                    if self.mask[idx] :\n",
    "                        if self.volume is not None :\n",
    "                            if self.df is not None :\n",
    "                                self.volume[:,*idx] -= self.df[idx]\n",
    "                            if self.bg is not None :\n",
    "                                self.volume[:,*idx] /= self.bg[idx]\n",
    "                        if  xCr + DatasetConfig.sinoWid < self.fsh[1] \\\n",
    "                        and np.all( self.mask[yCr,xCr+1:xCr+DatasetConfig.sinoWid] ) :\n",
    "                            self.allIndices.append(idx)\n",
    "\n",
    "    def get_dataset(self, transform=None) :\n",
    "        class Sinos(torch.utils.data.Dataset) :\n",
    "            def __init__(self, root, transform=None):\n",
    "                self.container = root\n",
    "                self.transform = transforms.Compose([transforms.ToTensor(), transform]) \\\n",
    "                    if transform else transforms.ToTensor()\n",
    "            def __len__(self):\n",
    "                return len(self.container.allIndices)\n",
    "            def __getitem__(self, index):\n",
    "                idx = self.container.allIndices[index]\n",
    "                xyrng=np.s_[ idx[0], idx[1]:idx[1]+DatasetConfig.sinoWid ]\n",
    "                if self.container.volume is not None :\n",
    "                    data = self.container.volume[:, *xyrng]\n",
    "                else :\n",
    "                    data = self.container.data[:, *xyrng]\n",
    "                    if self.container.df is not None :\n",
    "                        data -= self.container.df[None,*xyrng]\n",
    "                    if self.container.bg is not None :\n",
    "                        data /= self.container.bg[None,*xyrng]\n",
    "                if self.transform :\n",
    "                    data = self.transform(data)\n",
    "                return data\n",
    "        return Sinos(self, transform)\n",
    "\n",
    "\n",
    "    def get_data_loader(self, batch_size, shuffle=None, num_workers=os.cpu_count() ) :\n",
    "        return torch.utils.data.DataLoader( self.get_dataset(),\n",
    "                                            batch_size=batch_size,\n",
    "                                            num_workers=num_workers,\n",
    "                                            shuffle = shuffle)\n",
    "\n",
    "sinoRoot = StripesFromHDF(\"/mnt/ssdData/4176862R_Eig_Threshold-4keV/input/SAMPLE_Y0.hdf:/entry/data/data\",\n",
    "                          \"/mnt/ssdData/4176862R_Eig_Threshold-4keV/input/mask.tif\",\n",
    "                          \"/mnt/ssdData/4176862R_Eig_Threshold-4keV/output/bgo.tif\",\n",
    "                          None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTransform =  transforms.Compose([\n",
    "    transforms.Resize((DatasetConfig.sinoLen, DatasetConfig.sinoWid)),\n",
    "    transforms.Normalize(mean=(0.5), std=(0.5))\n",
    "])\n",
    "\n",
    "trainSet = sinoRoot.get_dataset(dataTransform)\n",
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    dataset=trainSet,\n",
    "    batch_size=TrainingConfig.batchSize,\n",
    "    shuffle=True,\n",
    "    num_workers=os.cpu_count()\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataTransform =  transforms.Compose([\n",
    "#    transforms.Resize((DatasetConfig.sinoLen, DatasetConfig.sinoWid)),\n",
    "#    #transforms.Resize((500, 500)),\n",
    "#    transforms.Normalize(mean=(0.5), std=(0.5))\n",
    "#])\n",
    "#\n",
    "#testSet = sinoRoot.get_dataset(dataTransform)\n",
    "#randIdx = random.randint(0,len(testSet)-1)\n",
    "#print(randIdx, sinoRoot.allIndices[randIdx])\n",
    "#image = testSet[randIdx].squeeze().transpose(0,1)\n",
    "#plt.imshow(image, cmap='gray')\n",
    "#plt.axis(\"off\")\n",
    "##tifffile.imwrite(\"tmp.tif\", image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">Save/Load model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, device, model_path):\n",
    "    if not device == 'cpu':\n",
    "        model.to('cpu')\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    if not device == 'cpu':\n",
    "        model.to(device)\n",
    "    return\n",
    "\n",
    "def load_model(model, model_path):\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "source": [
    "## <font style=\"color:blue\">Models</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (body): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(5, 3), stride=(1, 1), padding=same, bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 1), bias=False)\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "    (5): LeakyReLU(negative_slope=0.2)\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 1), bias=False)\n",
      "    (7): LeakyReLU(negative_slope=0.2)\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "    (9): LeakyReLU(negative_slope=0.2)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "    (11): LeakyReLU(negative_slope=0.2)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(2, 2), bias=False)\n",
      "    (13): LeakyReLU(negative_slope=0.2)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(4, 4), bias=False)\n",
      "    (15): LeakyReLU(negative_slope=0.2)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(8, 8), bias=False)\n",
      "    (17): LeakyReLU(negative_slope=0.2)\n",
      "    (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(16, 16), bias=False)\n",
      "    (19): LeakyReLU(negative_slope=0.2)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "    (21): LeakyReLU(negative_slope=0.2)\n",
      "    (22): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "    (23): LeakyReLU(negative_slope=0.2)\n",
      "    (24): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 1), bias=False)\n",
      "    (25): LeakyReLU(negative_slope=0.2)\n",
      "    (26): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "    (27): LeakyReLU(negative_slope=0.2)\n",
      "    (28): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 1), bias=False)\n",
      "    (29): LeakyReLU(negative_slope=0.2)\n",
      "    (30): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "    (31): LeakyReLU(negative_slope=0.2)\n",
      "    (32): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (33): Tanh()\n",
      "  )\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Generator                                [1, 1, 4096, 36]          --\n",
      "├─Sequential: 1-1                        [1, 1, 4096, 12]          --\n",
      "│    └─Conv2d: 2-1                       [1, 64, 4096, 12]         2,880\n",
      "│    └─LeakyReLU: 2-2                    [1, 64, 4096, 12]         --\n",
      "│    └─Conv2d: 2-3                       [1, 128, 2047, 10]        73,728\n",
      "│    └─LeakyReLU: 2-4                    [1, 128, 2047, 10]        --\n",
      "│    └─Conv2d: 2-5                       [1, 128, 2047, 10]        147,456\n",
      "│    └─LeakyReLU: 2-6                    [1, 128, 2047, 10]        --\n",
      "│    └─Conv2d: 2-7                       [1, 256, 1023, 8]         294,912\n",
      "│    └─LeakyReLU: 2-8                    [1, 256, 1023, 8]         --\n",
      "│    └─Conv2d: 2-9                       [1, 256, 1023, 8]         589,824\n",
      "│    └─LeakyReLU: 2-10                   [1, 256, 1023, 8]         --\n",
      "│    └─Conv2d: 2-11                      [1, 256, 1023, 8]         589,824\n",
      "│    └─LeakyReLU: 2-12                   [1, 256, 1023, 8]         --\n",
      "│    └─Conv2d: 2-13                      [1, 256, 1023, 8]         589,824\n",
      "│    └─LeakyReLU: 2-14                   [1, 256, 1023, 8]         --\n",
      "│    └─Conv2d: 2-15                      [1, 256, 1023, 8]         589,824\n",
      "│    └─LeakyReLU: 2-16                   [1, 256, 1023, 8]         --\n",
      "│    └─Conv2d: 2-17                      [1, 256, 1023, 8]         589,824\n",
      "│    └─LeakyReLU: 2-18                   [1, 256, 1023, 8]         --\n",
      "│    └─Conv2d: 2-19                      [1, 256, 1023, 8]         589,824\n",
      "│    └─LeakyReLU: 2-20                   [1, 256, 1023, 8]         --\n",
      "│    └─Conv2d: 2-21                      [1, 256, 1023, 8]         589,824\n",
      "│    └─LeakyReLU: 2-22                   [1, 256, 1023, 8]         --\n",
      "│    └─Conv2d: 2-23                      [1, 256, 1023, 8]         589,824\n",
      "│    └─LeakyReLU: 2-24                   [1, 256, 1023, 8]         --\n",
      "│    └─ConvTranspose2d: 2-25             [1, 128, 2048, 11]        524,288\n",
      "│    └─LeakyReLU: 2-26                   [1, 128, 2048, 11]        --\n",
      "│    └─Conv2d: 2-27                      [1, 128, 2048, 11]        147,456\n",
      "│    └─LeakyReLU: 2-28                   [1, 128, 2048, 11]        --\n",
      "│    └─ConvTranspose2d: 2-29             [1, 64, 4098, 14]         131,072\n",
      "│    └─LeakyReLU: 2-30                   [1, 64, 4098, 14]         --\n",
      "│    └─Conv2d: 2-31                      [1, 16, 4098, 14]         9,216\n",
      "│    └─LeakyReLU: 2-32                   [1, 16, 4098, 14]         --\n",
      "│    └─Conv2d: 2-33                      [1, 1, 4096, 12]          144\n",
      "│    └─Tanh: 2-34                        [1, 1, 4096, 12]          --\n",
      "==========================================================================================\n",
      "Total params: 6,049,744\n",
      "Trainable params: 6,049,744\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 68.89\n",
      "==========================================================================================\n",
      "Input size (MB): 0.59\n",
      "Forward/backward pass size (MB): 301.18\n",
      "Params size (MB): 24.20\n",
      "Estimated Total Size (MB): 325.97\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.body = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(3, 64, (5,3), bias=False, padding='same'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, stride=(2,1), bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 128, 3, bias=False, padding='same'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, stride=(2,1), bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 256, 3, bias=False, padding='same'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 256, 3, bias=False, padding='same'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 256, 3, dilation=2, bias=False, padding='same'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 256, 3, dilation=4, bias=False, padding='same'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 256, 3, dilation=8, bias=False, padding='same'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 256, 3, dilation=16, bias=False, padding='same'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 256, 3, bias=False, padding='same'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 256, 3, bias=False, padding='same'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=(2,1), bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 128, 3, bias=False, padding='same'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=(2,1), bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 16, 3, bias=False, padding='same'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(16, 1, 3, bias=False),\n",
    "            nn.Tanh()\n",
    "\n",
    "        )\n",
    "        torch.nn.init.xavier_uniform_(self.body[0].weight)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.view(input.shape[0], 3, DatasetConfig.sinoLen, DatasetConfig.gapWidth)\n",
    "        conv = self.body(input)\n",
    "        input[:,1,:,:] = conv\n",
    "        return input.view(input.shape[0], 1, DatasetConfig.sinoLen, DatasetConfig.sinoWid)\n",
    "\n",
    "\n",
    "\n",
    "#if model is not None:\n",
    "#    del model\n",
    "#    gc.collect()\n",
    "#    torch.cuda.empty_cache()\n",
    "generator = Generator()\n",
    "#model = load_model(model, \"/home/imbl/usr/src/ReMuse/experiments/e0134_model.pt\")\n",
    "print(generator)\n",
    "model_summary = summary(generator, (1,1,DatasetConfig.sinoLen,DatasetConfig.sinoWid) ).__str__()\n",
    "print(model_summary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (body): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(5, 3), stride=(2, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Conv2d(64, 128, kernel_size=(5, 3), stride=(2, 1), bias=False)\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): Conv2d(128, 256, kernel_size=(5, 3), stride=(2, 1), bias=False)\n",
      "    (5): LeakyReLU(negative_slope=0.2)\n",
      "    (6): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 1), bias=False)\n",
      "    (7): LeakyReLU(negative_slope=0.2)\n",
      "    (8): Conv2d(512, 512, kernel_size=(5, 5), stride=(2, 1), bias=False)\n",
      "    (9): LeakyReLU(negative_slope=0.2)\n",
      "    (10): Conv2d(512, 512, kernel_size=(5, 5), stride=(2, 1), bias=False)\n",
      "    (11): LeakyReLU(negative_slope=0.2)\n",
      "    (12): Conv2d(512, 512, kernel_size=(5, 5), stride=(2, 1), bias=False)\n",
      "    (13): LeakyReLU(negative_slope=0.2)\n",
      "    (14): Conv2d(512, 512, kernel_size=(5, 5), stride=(2, 1), bias=False)\n",
      "    (15): LeakyReLU(negative_slope=0.2)\n",
      "    (16): Conv2d(512, 512, kernel_size=(5, 5), stride=(2, 1), bias=False)\n",
      "    (17): LeakyReLU(negative_slope=0.2)\n",
      "    (18): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "    (19): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Dropout(p=0.4, inplace=False)\n",
      "    (2): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Discriminator                            [1, 1]                    --\n",
      "├─Sequential: 1-1                        [1, 512, 1, 2]            --\n",
      "│    └─Conv2d: 2-1                       [1, 64, 2046, 34]         960\n",
      "│    └─LeakyReLU: 2-2                    [1, 64, 2046, 34]         --\n",
      "│    └─Conv2d: 2-3                       [1, 128, 1021, 32]        122,880\n",
      "│    └─LeakyReLU: 2-4                    [1, 128, 1021, 32]        --\n",
      "│    └─Conv2d: 2-5                       [1, 256, 509, 30]         491,520\n",
      "│    └─LeakyReLU: 2-6                    [1, 256, 509, 30]         --\n",
      "│    └─Conv2d: 2-7                       [1, 512, 253, 26]         3,276,800\n",
      "│    └─LeakyReLU: 2-8                    [1, 512, 253, 26]         --\n",
      "│    └─Conv2d: 2-9                       [1, 512, 125, 22]         6,553,600\n",
      "│    └─LeakyReLU: 2-10                   [1, 512, 125, 22]         --\n",
      "│    └─Conv2d: 2-11                      [1, 512, 61, 18]          6,553,600\n",
      "│    └─LeakyReLU: 2-12                   [1, 512, 61, 18]          --\n",
      "│    └─Conv2d: 2-13                      [1, 512, 29, 14]          6,553,600\n",
      "│    └─LeakyReLU: 2-14                   [1, 512, 29, 14]          --\n",
      "│    └─Conv2d: 2-15                      [1, 512, 13, 10]          6,553,600\n",
      "│    └─LeakyReLU: 2-16                   [1, 512, 13, 10]          --\n",
      "│    └─Conv2d: 2-17                      [1, 512, 5, 6]            6,553,600\n",
      "│    └─LeakyReLU: 2-18                   [1, 512, 5, 6]            --\n",
      "│    └─Conv2d: 2-19                      [1, 512, 1, 2]            6,553,600\n",
      "│    └─LeakyReLU: 2-20                   [1, 512, 1, 2]            --\n",
      "├─Sequential: 1-2                        [1, 1]                    --\n",
      "│    └─Flatten: 2-21                     [1, 1024]                 --\n",
      "│    └─Dropout: 2-22                     [1, 1024]                 --\n",
      "│    └─Linear: 2-23                      [1, 1]                    1,025\n",
      "│    └─Sigmoid: 2-24                     [1, 1]                    --\n",
      "==========================================================================================\n",
      "Total params: 43,214,785\n",
      "Trainable params: 43,214,785\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 62.08\n",
      "==========================================================================================\n",
      "Input size (MB): 0.59\n",
      "Forward/backward pass size (MB): 145.38\n",
      "Params size (MB): 172.86\n",
      "Estimated Total Size (MB): 318.83\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.body = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(1, 64, (5,3), stride=(2,1), bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 128, (5,3), stride=(2,1), bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 256, (5,3), stride=(2,1), bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 512, 5, stride=(2,1), bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(512, 512, 5, stride=(2,1), bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(512, 512, 5, stride=(2,1), bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(512, 512, 5, stride=(2,1), bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(512, 512, 5, stride=(2,1), bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(512, 512, 5, stride=(2,1), bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(512, 512, 5, bias=False),\n",
    "            nn.LeakyReLU(0.2)\n",
    "\n",
    "        )\n",
    "        torch.nn.init.xavier_uniform_(self.body[0].weight)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        conv = self.body(input)\n",
    "        res = self.head(conv)\n",
    "        return res\n",
    "\n",
    "\n",
    "discriminator = Discriminator()\n",
    "#model = load_model(model, \"/home/imbl/usr/src/ReMuse/experiments/e0134_model.pt\")\n",
    "print(discriminator)\n",
    "model_summary = summary(discriminator, (1,1,DatasetConfig.sinoLen,DatasetConfig.sinoWid) ).__str__()\n",
    "print(model_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">Metrics</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCE = nn.BCELoss()\n",
    "\n",
    "def loss_func(y_true, y_pred):\n",
    "    loss = BCE(y_pred, y_true)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">Optimizers</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer_G = optim.Adam(\n",
    "    generator.parameters(),\n",
    "    lr=TrainingConfig.learningRateG,\n",
    "    betas=(0.5, 0.999)\n",
    ")\n",
    "optimizer_D = optim.Adam(\n",
    "    discriminator.parameters(),\n",
    "    lr=TrainingConfig.learningRateD,\n",
    "    betas=(0.5, 0.999)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">Train step</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images):\n",
    "\n",
    "    optimizer_G.zero_grad()\n",
    "    optimizer_D.zero_grad()\n",
    "\n",
    "    y_pred_real = discriminator(images)\n",
    "    noise = torch.randn(images.shape[0],\n",
    "                        DatasetConfig.sinoLen,\n",
    "                        DatasetConfig.gapWidth).to(TrainingConfig.device)\n",
    "    images[:,:,DatasetConfig.gapWidth:2*DatasetConfig.gapWidth] = noise\n",
    "    y_pred_fake = discriminator(images)\n",
    "    y_pred_both = torch.cat((y_pred_real, y_pred_fake), dim=0)\n",
    "    labels = torch.cat(\n",
    "        torch.full((TrainingConfig.batchSize, 1),  TrainingConfig.labelSmoothFac), # Labels for real data\n",
    "        torch.zeros(TrainingConfig.batchSize, 1), # Labels for fake data\n",
    "        dim=0\n",
    "    ).to(TrainingConfig.DEVICE)\n",
    "\n",
    "    D_loss = loss_func(labels, y_pred_both)\n",
    "    D_loss.backward()\n",
    "    optimizer_D.step()\n",
    "\n",
    "    labels = torch.ones(TrainingConfig.batchSize, 1)\n",
    "    G_loss = loss_func(labels, y_pred_fake)\n",
    "    G_loss.backward()\n",
    "    optimizer_G.step()\n",
    "\n",
    "    return D_loss, G_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
