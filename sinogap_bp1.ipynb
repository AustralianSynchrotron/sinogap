{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Header</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Imports</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import sinogap_module_alt as sg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Redefine</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.plt.rcParams['figure.dpi']=223\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Configs</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.set_seed(7)\n",
    "\n",
    "sg.TCfg = sg.TCfgClass(\n",
    "     exec = 1\n",
    "    ,nofEpochs = None\n",
    "    ,latentDim = 64\n",
    "    ,batchSize = 2**5\n",
    "    ,batchSplit = 1\n",
    "    ,labelSmoothFac = 0.1 # For Fake labels (or set to 0.0 for no smoothing).\n",
    "    ,learningRateD = 0.0001\n",
    "    ,learningRateG = 0.0001\n",
    ")\n",
    "\n",
    "sg.DCfg = sg.DCfgClass(16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Raw Read</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train set 1 of 9: 18515.Lamb1_Eiger_7m_45keV_360Scan ... Done\n",
      "Loading train set 2 of 9: 18692a.ExpChicken6mGyShift ... Done\n",
      "Loading train set 3 of 9: 18692b_input_PhantomM ... Done\n",
      "Loading train set 4 of 9: 18692b.MinceO ... Done\n",
      "Loading train set 5 of 9: 19022g.11-EggLard ... Done\n",
      "Loading train set 6 of 9: 19736b.09_Feb.4176862R_Eig_Threshold-4keV ... Done\n",
      "Loading train set 7 of 9: 19736c.8733147R_Eig_Threshold-8keV.SAMPLE_Y1 ... Done\n",
      "Loading train set 8 of 9: 20982b.04_774784R ... Done\n",
      "Loading train set 9 of 9: 23574.8965435L.Eiger.32kev_org ... Done\n"
     ]
    }
   ],
   "source": [
    "trainSet = sg.createTrainSet()\n",
    "#testSet = sg.createTestSet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Show</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sg.refImages, sg.refNoises = sg.createReferences(testSet, 1)\n",
    "#sg.showMe(testSet, 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "source": [
    "## <font style=\"color:lightblue\">Models</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator 2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Generator2(sg.GeneratorTemplate):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator2, self).__init__(2)\n",
    "        self.amplitude = 4\n",
    "        self.encoders =  nn.ModuleList([\n",
    "            self.encblock(  1/self.baseChannels,\n",
    "                               1, 3, padding=1, norm=False),\n",
    "            self.encblock(  1, 1, 3, padding=1),\n",
    "            self.encblock(  1, 1, 3, stride=(2,1), padding=(1,0)),\n",
    "            self.encblock(  1, 1, 3, padding=1),\n",
    "            self.encblock(  1, 1, 3, stride=(2,1), padding=(1,0)),\n",
    "            self.encblock(  1, 1, 3, padding=1),\n",
    "            self.encblock(  1, 1, 3, stride=(2,1), padding=(1,0)),\n",
    "            #self.encblock(  1, 1, 3, padding=1),\n",
    "            #self.encblock(  1, 1, 3, stride=(2,1), padding=(1,0)),\n",
    "            ])\n",
    "        self.fcLink = self.createFClink()\n",
    "        self.decoders = nn.ModuleList([\n",
    "            #self.decblock(2, 1, 3, stride=(2,1), outputPadding=(1,0), padding=(1,0)),\n",
    "            #self.decblock(2, 1, 3, padding=1),\n",
    "            self.decblock(2, 1, 3, stride=(2,1), outputPadding=(1,0), padding=(1,0)),\n",
    "            self.decblock(2, 1, 3, padding=1),\n",
    "            self.decblock(2, 1, 3, stride=(2,1), outputPadding=(1,0), padding=(1,0)),\n",
    "            self.decblock(2, 1, 3, padding=1),\n",
    "            self.decblock(2, 1, 3, stride=(2,1), outputPadding=(1,0), padding=(1,0)),\n",
    "            self.decblock(2, 1, 3, padding=1),\n",
    "            self.decblock(2, 1, 3, padding=1, norm=False),\n",
    "            ])\n",
    "        self.lastTouch = self.createLastTouch()\n",
    "        #sg.load_model(self, model_path=\"saves/gap2/noBNreNorm_SSIM/model_gen.pt\" )\n",
    "\n",
    "#generator2 = Generator2()\n",
    "#generator2 = generator2.to(sg.TCfg.device)\n",
    "#generator2 = generator2.requires_grad_(False)\n",
    "#generator2 = generator2.eval()\n",
    "#sg.lowResGenerators[2] = generator2\n",
    "#\n",
    "#input_data=[ (torch.randn( (1,1,*generator2.sinoSh), device=sg.TCfg.device),\n",
    "#              torch.randn( (1,sg.TCfg.latentDim), device=sg.TCfg.device)) ]\n",
    "#model_summary = summary(generator2, input_data=input_data ).__str__()\n",
    "#print(model_summary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator 4pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Generator4(sg.GeneratorTemplate):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator4, self).__init__(4)\n",
    "        self.amplitude = 4\n",
    "        self.encoders =  nn.ModuleList([\n",
    "            self.encblock( 1/self.baseChannels,\n",
    "                               1, 3, padding=1, norm=False),\n",
    "            self.encblock(  1, 1, 3, padding=1),\n",
    "            self.encblock(  1, 2, 3, stride=(2,2), padding=(1,1)),\n",
    "            self.encblock(  2, 2, 3, padding=1),\n",
    "            self.encblock(  2, 2, 3, stride=(2,1), padding=(1,0)),\n",
    "            self.encblock(  2, 2, 3, padding=1),\n",
    "            self.encblock(  2, 2, 3, stride=(2,1), padding=(1,0)),\n",
    "            self.encblock(  2, 2, 3, padding=1),\n",
    "            self.encblock(  2, 2, 3, stride=(2,1), padding=(1,0)),\n",
    "            ])\n",
    "        self.fcLink = self.createFClink()\n",
    "        self.decoders = nn.ModuleList([\n",
    "            self.decblock(4, 2, 3, stride=(2,1), outputPadding=(1,0), padding=(1,0)),\n",
    "            self.decblock(4, 2, 3, padding=1),\n",
    "            self.decblock(4, 2, 3, stride=(2,1), outputPadding=(1,0), padding=(1,0)),\n",
    "            self.decblock(4, 2, 3, padding=1),\n",
    "            self.decblock(4, 2, 3, stride=(2,1), outputPadding=(1,0), padding=(1,0)),\n",
    "            self.decblock(4, 2, 3, padding=1),\n",
    "            self.decblock(4, 1, 3, stride=(2,2), outputPadding=(1,1), padding=(1,1)),\n",
    "            self.decblock(2, 1, 3, padding=1),\n",
    "            self.decblock(2, 1, 3, padding=1, norm=False),\n",
    "            ])\n",
    "        self.lastTouch = self.createLastTouch()\n",
    "        self.lowResGenerator = Generator2()\n",
    "        #sg.load_model(self, model_path=\"saves/gap4/noBNreNorm_SSIM/model_gen.pt\" )\n",
    "\n",
    "#generator4 = Generator4()\n",
    "#generator4 = generator4.to(sg.TCfg.device)\n",
    "#generator4 = generator4.requires_grad_(False)\n",
    "#generator4 = generator4.eval()\n",
    "#sg.lowResGenerators[4] = generator4\n",
    "#\n",
    "#input_data=[ (torch.randn( (1,1,*generator4.sinoSh), device=sg.TCfg.device),\n",
    "#              torch.randn( (1,sg.TCfg.latentDim), device=sg.TCfg.device)) ]\n",
    "#model_summary = summary(generator4, input_data=input_data ).__str__()\n",
    "#print(model_summary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator 8pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Generator8(sg.GeneratorTemplate):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator8, self).__init__(8)\n",
    "        self.amplitude = 4\n",
    "\n",
    "        self.encoders =  nn.ModuleList([\n",
    "            self.encblock( 1/self.baseChannels,\n",
    "                               1, 3, padding=1, norm=False),\n",
    "            self.encblock(  1, 1, 3, padding=1),\n",
    "            self.encblock(  1, 2, 3, stride=(2,2), padding=(1,1)),\n",
    "            self.encblock(  2, 2, 3, padding=1),\n",
    "            self.encblock(  2, 4, 3, stride=(2,2), padding=(1,1)),\n",
    "            self.encblock(  4, 4, 3, padding=1),\n",
    "            self.encblock(  4, 4, 3, stride=(2,1), padding=(1,0)),\n",
    "            self.encblock(  4, 4, 3, padding=1),\n",
    "            self.encblock(  4, 4, 3, stride=(2,1), padding=(1,0)),\n",
    "            self.encblock(  4, 4, 3, padding=1),\n",
    "            self.encblock(  4, 4, 3, stride=(2,1), padding=(1,0)),\n",
    "            ])\n",
    "\n",
    "        self.fcLink = self.createFClink()\n",
    "\n",
    "        self.decoders = nn.ModuleList([\n",
    "            self.decblock(8, 4, 3, stride=(2,1), outputPadding=(1,0), padding=(1,0)),\n",
    "            self.decblock(8, 4, 3, padding=1),\n",
    "            self.decblock(8, 4, 3, stride=(2,1), outputPadding=(1,0), padding=(1,0)),\n",
    "            self.decblock(8, 4, 3, padding=1),\n",
    "            self.decblock(8, 4, 3, stride=(2,1), outputPadding=(1,0), padding=(1,0)),\n",
    "            self.decblock(8, 4, 3, padding=1),\n",
    "            self.decblock(8, 2, 3, stride=(2,2), outputPadding=(1,1), padding=(1,1)),\n",
    "            self.decblock(4, 2, 3, padding=1),\n",
    "            self.decblock(4, 1, 3, stride=(2,2), outputPadding=(1,1), padding=(1,1)),\n",
    "            self.decblock(2, 1, 3, padding=1),\n",
    "            self.decblock(2, 1, 3, padding=1, norm=False),\n",
    "            ])\n",
    "\n",
    "        self.lastTouch = self.createLastTouch()\n",
    "        self.lowResGenerator = Generator4()\n",
    "        #sg.load_model(self, model_path=\"saves/gap8/noBNreNorm_SSIM/model_gen.pt\" )\n",
    "\n",
    "\n",
    "#generator8 = Generator8()\n",
    "#generator8 = generator8.to(sg.TCfg.device)\n",
    "#generator8 = generator8.requires_grad_(False)\n",
    "#generator8 = generator8.eval()\n",
    "#sg.lowResGenerators[8] = generator8\n",
    "#\n",
    "#input_data=[ (torch.randn( (1,1,*generator8.sinoSh), device=sg.TCfg.device),\n",
    "#              torch.randn( (1,sg.TCfg.latentDim), device=sg.TCfg.device)) ]\n",
    "#model_summary = summary(generator8, input_data=input_data ).__str__()\n",
    "#print(model_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator 16pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Generator16(sg.GeneratorTemplate):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator16, self).__init__(16,1)\n",
    "        self.amplitude = 4\n",
    "\n",
    "        self.noise2latent = self.createLatent()\n",
    "\n",
    "        self.encoders =  nn.ModuleList([\n",
    "            self.encblock( (1+self.latentChannels)/self.baseChannels,\n",
    "                               1, 3, padding=1, norm=False),\n",
    "            self.encblock(  1, 1, 3, padding=1),\n",
    "            self.encblock(  1, 2, 3, stride=(2,2), padding=(1,1)),\n",
    "            self.encblock(  2, 2, 3, padding=1),\n",
    "            self.encblock(  2, 4, 3, stride=(2,2), padding=(1,1)),\n",
    "            self.encblock(  4, 4, 3, padding=1),\n",
    "            self.encblock(  4, 8, 3, stride=(2,2), padding=(1,1)),\n",
    "            self.encblock(  8, 8, 3, padding=1),\n",
    "            self.encblock(  8, 8, 3, stride=(2,1), padding=(1,0)),\n",
    "            self.encblock(  8, 8, 3, padding=1),\n",
    "            self.encblock(  8, 8, 3, stride=(2,1), padding=(1,0)),\n",
    "            self.encblock(  8, 8, 3, padding=1),\n",
    "            self.encblock(  8, 8, 3, stride=(2,1), padding=(1,0)),\n",
    "            ])\n",
    "\n",
    "        self.fcLink = self.createFClink()\n",
    "\n",
    "        self.decoders = nn.ModuleList([\n",
    "            self.decblock(16, 8, 3, stride=(2,1), outputPadding=(1,0), padding=(1,0)),\n",
    "            self.decblock(16, 8, 3, padding=1),\n",
    "            self.decblock(16, 8, 3, stride=(2,1), outputPadding=(1,0), padding=(1,0)),\n",
    "            self.decblock(16, 8, 3, padding=1),\n",
    "            self.decblock(16, 8, 3, stride=(2,1), outputPadding=(1,0), padding=(1,0)),\n",
    "            self.decblock(16, 8, 3, padding=1),\n",
    "            self.decblock(16, 4, 3, stride=(2,2), outputPadding=(1,1), padding=(1,1)),\n",
    "            self.decblock( 8, 4, 3, padding=1),\n",
    "            self.decblock( 8, 2, 3, stride=(2,2), outputPadding=(1,1), padding=(1,1)),\n",
    "            self.decblock( 4, 2, 3, padding=1),\n",
    "            self.decblock( 4, 1, 3, stride=(2,2), outputPadding=(1,1), padding=(1,1)),\n",
    "            self.decblock( 2, 1, 3, padding=1),\n",
    "            self.decblock( 2, 1, 3, padding=1, norm=False),\n",
    "            ])\n",
    "\n",
    "        self.lowResGenerator = Generator8()\n",
    "        self.lastTouch = self.createLastTouch()\n",
    "        #sg.load_model(self, model_path=\"saves/gap16/noBNreNorm_SSIM/model_gen.pt\" )\n",
    "\n",
    "generator16 = Generator16()\n",
    "generator16 = generator16.to(sg.TCfg.device)\n",
    "sg.lowResGenerators[16] = generator16\n",
    "#\n",
    "#input_data=[ (torch.randn( (1,1,*generator16.sinoSh), device=sg.TCfg.device),\n",
    "#              torch.randn( (1,sg.TCfg.latentDim), device=sg.TCfg.device)) ]\n",
    "#model_summary = summary(generator16, input_data=input_data ).__str__()\n",
    "#print(model_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Generator</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================\n",
      "Layer (type:depth-idx)                                  Output Shape              Param #\n",
      "=========================================================================================================\n",
      "Generator16                                             [1, 1, 4096, 16]          --\n",
      "├─Generator8: 1-1                                       --                        --\n",
      "│    └─Generator4: 2-1                                  --                        --\n",
      "│    │    └─Generator2: 3-1                             --                        2,102,178\n",
      "│    │    └─ModuleList: 3-2                             --                        3,988\n",
      "│    │    └─Sequential: 3-3                             [1, 8, 64, 4]             8,392,704\n",
      "│    │    └─ModuleList: 3-4                             --                        8,124\n",
      "│    │    └─Sequential: 3-5                             [1, 1, 1024, 20]          6\n",
      "│    └─ModuleList: 2-2                                  --                        --\n",
      "│    │    └─Sequential: 3-6                             [1, 4, 2048, 40]          40\n",
      "│    │    └─Sequential: 3-7                             [1, 4, 2048, 40]          148\n",
      "│    │    └─Sequential: 3-8                             [1, 8, 1024, 20]          296\n",
      "│    │    └─Sequential: 3-9                             [1, 8, 1024, 20]          584\n",
      "│    │    └─Sequential: 3-10                            [1, 16, 512, 10]          1,168\n",
      "│    │    └─Sequential: 3-11                            [1, 16, 512, 10]          2,320\n",
      "│    │    └─Sequential: 3-12                            [1, 16, 256, 8]           2,320\n",
      "│    │    └─Sequential: 3-13                            [1, 16, 256, 8]           2,320\n",
      "│    │    └─Sequential: 3-14                            [1, 16, 128, 6]           2,320\n",
      "│    │    └─Sequential: 3-15                            [1, 16, 128, 6]           2,320\n",
      "│    │    └─Sequential: 3-16                            [1, 16, 64, 4]            2,320\n",
      "│    └─Sequential: 2-3                                  [1, 16, 64, 4]            --\n",
      "│    │    └─Flatten: 3-17                               [1, 4096]                 --\n",
      "│    │    └─Linear: 3-18                                [1, 4096]                 16,781,312\n",
      "│    │    └─LeakyReLU: 3-19                             [1, 4096]                 --\n",
      "│    │    └─Linear: 3-20                                [1, 4096]                 16,781,312\n",
      "│    │    └─LeakyReLU: 3-21                             [1, 4096]                 --\n",
      "│    │    └─Unflatten: 3-22                             [1, 16, 64, 4]            --\n",
      "│    └─ModuleList: 2-4                                  --                        --\n",
      "│    │    └─Sequential: 3-23                            [1, 16, 128, 6]           4,624\n",
      "│    │    └─Sequential: 3-24                            [1, 16, 128, 6]           4,624\n",
      "│    │    └─Sequential: 3-25                            [1, 16, 256, 8]           4,624\n",
      "│    │    └─Sequential: 3-26                            [1, 16, 256, 8]           4,624\n",
      "│    │    └─Sequential: 3-27                            [1, 16, 512, 10]          4,624\n",
      "│    │    └─Sequential: 3-28                            [1, 16, 512, 10]          4,624\n",
      "│    │    └─Sequential: 3-29                            [1, 8, 1024, 20]          2,312\n",
      "│    │    └─Sequential: 3-30                            [1, 8, 1024, 20]          1,160\n",
      "│    │    └─Sequential: 3-31                            [1, 4, 2048, 40]          580\n",
      "│    │    └─Sequential: 3-32                            [1, 4, 2048, 40]          292\n",
      "│    │    └─Sequential: 3-33                            [1, 4, 2048, 40]          292\n",
      "│    └─Sequential: 2-5                                  [1, 1, 2048, 40]          --\n",
      "│    │    └─Conv2d: 3-34                                [1, 1, 2048, 40]          6\n",
      "│    │    └─Tanh: 3-35                                  [1, 1, 2048, 40]          --\n",
      "├─Sequential: 1-2                                       [1, 1, 4096, 80]          --\n",
      "│    └─Linear: 2-6                                      [1, 327680]               21,299,200\n",
      "│    └─ReLU: 2-7                                        [1, 327680]               --\n",
      "│    └─Unflatten: 2-8                                   [1, 1, 4096, 80]          --\n",
      "├─ModuleList: 1-3                                       --                        --\n",
      "│    └─Sequential: 2-9                                  [1, 4, 4096, 80]          --\n",
      "│    │    └─Conv2d: 3-36                                [1, 4, 4096, 80]          76\n",
      "│    │    └─LeakyReLU: 3-37                             [1, 4, 4096, 80]          --\n",
      "│    └─Sequential: 2-10                                 [1, 4, 4096, 80]          --\n",
      "│    │    └─Conv2d: 3-38                                [1, 4, 4096, 80]          148\n",
      "│    │    └─LeakyReLU: 3-39                             [1, 4, 4096, 80]          --\n",
      "│    └─Sequential: 2-11                                 [1, 8, 2048, 40]          --\n",
      "│    │    └─Conv2d: 3-40                                [1, 8, 2048, 40]          296\n",
      "│    │    └─LeakyReLU: 3-41                             [1, 8, 2048, 40]          --\n",
      "│    └─Sequential: 2-12                                 [1, 8, 2048, 40]          --\n",
      "│    │    └─Conv2d: 3-42                                [1, 8, 2048, 40]          584\n",
      "│    │    └─LeakyReLU: 3-43                             [1, 8, 2048, 40]          --\n",
      "│    └─Sequential: 2-13                                 [1, 16, 1024, 20]         --\n",
      "│    │    └─Conv2d: 3-44                                [1, 16, 1024, 20]         1,168\n",
      "│    │    └─LeakyReLU: 3-45                             [1, 16, 1024, 20]         --\n",
      "│    └─Sequential: 2-14                                 [1, 16, 1024, 20]         --\n",
      "│    │    └─Conv2d: 3-46                                [1, 16, 1024, 20]         2,320\n",
      "│    │    └─LeakyReLU: 3-47                             [1, 16, 1024, 20]         --\n",
      "│    └─Sequential: 2-15                                 [1, 32, 512, 10]          --\n",
      "│    │    └─Conv2d: 3-48                                [1, 32, 512, 10]          4,640\n",
      "│    │    └─LeakyReLU: 3-49                             [1, 32, 512, 10]          --\n",
      "│    └─Sequential: 2-16                                 [1, 32, 512, 10]          --\n",
      "│    │    └─Conv2d: 3-50                                [1, 32, 512, 10]          9,248\n",
      "│    │    └─LeakyReLU: 3-51                             [1, 32, 512, 10]          --\n",
      "│    └─Sequential: 2-17                                 [1, 32, 256, 8]           --\n",
      "│    │    └─Conv2d: 3-52                                [1, 32, 256, 8]           9,248\n",
      "│    │    └─LeakyReLU: 3-53                             [1, 32, 256, 8]           --\n",
      "│    └─Sequential: 2-18                                 [1, 32, 256, 8]           --\n",
      "│    │    └─Conv2d: 3-54                                [1, 32, 256, 8]           9,248\n",
      "│    │    └─LeakyReLU: 3-55                             [1, 32, 256, 8]           --\n",
      "│    └─Sequential: 2-19                                 [1, 32, 128, 6]           --\n",
      "│    │    └─Conv2d: 3-56                                [1, 32, 128, 6]           9,248\n",
      "│    │    └─LeakyReLU: 3-57                             [1, 32, 128, 6]           --\n",
      "│    └─Sequential: 2-20                                 [1, 32, 128, 6]           --\n",
      "│    │    └─Conv2d: 3-58                                [1, 32, 128, 6]           9,248\n",
      "│    │    └─LeakyReLU: 3-59                             [1, 32, 128, 6]           --\n",
      "│    └─Sequential: 2-21                                 [1, 32, 64, 4]            --\n",
      "│    │    └─Conv2d: 3-60                                [1, 32, 64, 4]            9,248\n",
      "│    │    └─LeakyReLU: 3-61                             [1, 32, 64, 4]            --\n",
      "├─Sequential: 1-4                                       [1, 32, 64, 4]            --\n",
      "│    └─Flatten: 2-22                                    [1, 8192]                 --\n",
      "│    └─Linear: 2-23                                     [1, 8192]                 67,117,056\n",
      "│    └─LeakyReLU: 2-24                                  [1, 8192]                 --\n",
      "│    └─Linear: 2-25                                     [1, 8192]                 67,117,056\n",
      "│    └─LeakyReLU: 2-26                                  [1, 8192]                 --\n",
      "│    └─Unflatten: 2-27                                  [1, 32, 64, 4]            --\n",
      "├─ModuleList: 1-5                                       --                        --\n",
      "│    └─Sequential: 2-28                                 [1, 32, 128, 6]           --\n",
      "│    │    └─ConvTranspose2d: 3-62                       [1, 32, 128, 6]           18,464\n",
      "│    │    └─LeakyReLU: 3-63                             [1, 32, 128, 6]           --\n",
      "│    └─Sequential: 2-29                                 [1, 32, 128, 6]           --\n",
      "│    │    └─ConvTranspose2d: 3-64                       [1, 32, 128, 6]           18,464\n",
      "│    │    └─LeakyReLU: 3-65                             [1, 32, 128, 6]           --\n",
      "│    └─Sequential: 2-30                                 [1, 32, 256, 8]           --\n",
      "│    │    └─ConvTranspose2d: 3-66                       [1, 32, 256, 8]           18,464\n",
      "│    │    └─LeakyReLU: 3-67                             [1, 32, 256, 8]           --\n",
      "│    └─Sequential: 2-31                                 [1, 32, 256, 8]           --\n",
      "│    │    └─ConvTranspose2d: 3-68                       [1, 32, 256, 8]           18,464\n",
      "│    │    └─LeakyReLU: 3-69                             [1, 32, 256, 8]           --\n",
      "│    └─Sequential: 2-32                                 [1, 32, 512, 10]          --\n",
      "│    │    └─ConvTranspose2d: 3-70                       [1, 32, 512, 10]          18,464\n",
      "│    │    └─LeakyReLU: 3-71                             [1, 32, 512, 10]          --\n",
      "│    └─Sequential: 2-33                                 [1, 32, 512, 10]          --\n",
      "│    │    └─ConvTranspose2d: 3-72                       [1, 32, 512, 10]          18,464\n",
      "│    │    └─LeakyReLU: 3-73                             [1, 32, 512, 10]          --\n",
      "│    └─Sequential: 2-34                                 [1, 16, 1024, 20]         --\n",
      "│    │    └─ConvTranspose2d: 3-74                       [1, 16, 1024, 20]         9,232\n",
      "│    │    └─LeakyReLU: 3-75                             [1, 16, 1024, 20]         --\n",
      "│    └─Sequential: 2-35                                 [1, 16, 1024, 20]         --\n",
      "│    │    └─ConvTranspose2d: 3-76                       [1, 16, 1024, 20]         4,624\n",
      "│    │    └─LeakyReLU: 3-77                             [1, 16, 1024, 20]         --\n",
      "│    └─Sequential: 2-36                                 [1, 8, 2048, 40]          --\n",
      "│    │    └─ConvTranspose2d: 3-78                       [1, 8, 2048, 40]          2,312\n",
      "│    │    └─LeakyReLU: 3-79                             [1, 8, 2048, 40]          --\n",
      "│    └─Sequential: 2-37                                 [1, 8, 2048, 40]          --\n",
      "│    │    └─ConvTranspose2d: 3-80                       [1, 8, 2048, 40]          1,160\n",
      "│    │    └─LeakyReLU: 3-81                             [1, 8, 2048, 40]          --\n",
      "│    └─Sequential: 2-38                                 [1, 4, 4096, 80]          --\n",
      "│    │    └─ConvTranspose2d: 3-82                       [1, 4, 4096, 80]          580\n",
      "│    │    └─LeakyReLU: 3-83                             [1, 4, 4096, 80]          --\n",
      "│    └─Sequential: 2-39                                 [1, 4, 4096, 80]          --\n",
      "│    │    └─ConvTranspose2d: 3-84                       [1, 4, 4096, 80]          292\n",
      "│    │    └─LeakyReLU: 3-85                             [1, 4, 4096, 80]          --\n",
      "│    └─Sequential: 2-40                                 [1, 4, 4096, 80]          --\n",
      "│    │    └─ConvTranspose2d: 3-86                       [1, 4, 4096, 80]          292\n",
      "│    │    └─LeakyReLU: 3-87                             [1, 4, 4096, 80]          --\n",
      "├─Sequential: 1-6                                       [1, 1, 4096, 80]          --\n",
      "│    └─Conv2d: 2-41                                     [1, 1, 4096, 80]          6\n",
      "│    └─Tanh: 2-42                                       [1, 1, 4096, 80]          --\n",
      "=========================================================================================================\n",
      "Total params: 199,845,480\n",
      "Trainable params: 199,845,480\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 2.15\n",
      "=========================================================================================================\n",
      "Input size (MB): 1.31\n",
      "Forward/backward pass size (MB): 127.39\n",
      "Params size (MB): 799.38\n",
      "Estimated Total Size (MB): 928.08\n",
      "=========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "sg.generator = sg.lowResGenerators[sg.DCfg.gapW]\n",
    "sg.optimizer_G = sg.createOptimizer(sg.generator, sg.TCfg.learningRateG)\n",
    "input_data=[ (torch.randn( (1,1,*sg.generator.sinoSh), device=sg.TCfg.device),\n",
    "              torch.randn( (1,sg.TCfg.latentDim), device=sg.TCfg.device)) ]\n",
    "#input_data=[ [sg.refImages[[0],...], sg.refNoises[[0],...]] ]\n",
    "model_summary = summary(sg.generator, input_data=input_data ).__str__()\n",
    "print(model_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Discriminator</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Discriminator(sg.DiscriminatorTemplate):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.param = nn.Parameter(torch.zeros(1))\n",
    "    def forward(self, images):\n",
    "        return torch.zeros((images.shape[0],1), device=sg.TCfg.device)\n",
    "\n",
    "\n",
    "sg.discriminator = Discriminator()\n",
    "sg.discriminator = sg.discriminator.to(sg.TCfg.device)\n",
    "#model_summary = summary(sg.discriminator, input_data=sg.refImages[0,...] ).__str__()\n",
    "model_summary = summary(sg.discriminator, input_data=torch.randn( (1,1,*sg.generator.sinoSh), device=sg.TCfg.device) ).__str__()\n",
    "#print(model_summary)\n",
    "#sg.writer.add_graph(sg.discriminator, refImages)\n",
    "\n",
    "sg.optimizer_D = sg.createOptimizer(sg.discriminator, sg.TCfg.learningRateD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Restore checkpoint</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.012063, 0.006625, 0.055)\n",
      "(0.009692, 0.00137, 0.03605)\n"
     ]
    }
   ],
   "source": [
    "sg.noAdv = True\n",
    "#sg.dataLoader = sg.createDataLoader(trainSet, num_workers=16)\n",
    "#sg.testLoader = sg.createDataLoader(testSet , num_workers=16)\n",
    "\n",
    "#sg.normRec, sg.normMSE, sg.normL1L = sg.summarizeSet(sg.dataLoader)[0:3]\n",
    "#sg.normTestRec, sg.normTestMSE, sg.normTestL1L, = sg.summarizeSet(sg.testLoader)[0:3]\n",
    "sg.normRec, sg.normMSE, sg.normL1L = 3 * 4.021e-03, 6.625e-03, 5.5e-02 #sg.summarizeSet(sg.dataLoader)[0:3]\n",
    "sg.normTestRec, sg.normTestMSE, sg.normTestL1L, = 2 * 4.846e-03, 1.370e-03, 3.605e-02 # sg.summarizeSet(sg.testLoader)[0:3]\n",
    "sg.normSSIM = sg.normL1L\n",
    "sg.normTestSSIM = sg.normTestL1L\n",
    "print((sg.normRec, sg.normMSE, sg.normL1L))\n",
    "print((sg.normTestRec, sg.normTestMSE, sg.normTestL1L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sg.scheduler_G = torch.optim.lr_scheduler.StepLR(sg.optimizer_G, 1, gamma=1-0.001)\n",
    "#sg.scheduler_D = torch.optim.lr_scheduler.StepLR(sg.optimizer_D, 1, gamma=1-0.001)\n",
    "savedCheckPoint = f\"checkPoint_{sg.TCfg.exec}\"\n",
    "sg.epoch, sg.imer, sg.minGEpoch, sg.minGdLoss, sg.startFrom, sg.resAcc = \\\n",
    "    sg.restoreCheckpoint()#savedCheckPoint+\".pth\")\n",
    "sg.writer = sg.createWriter(sg.TCfg.logDir, True)\n",
    "#sg.writer.add_graph(sg.generator, ((sg.refImages, sg.refNoises),) )\n",
    "#sg.writer.add_graph(sg.discriminator, refImages)\n",
    "#sg.minGdLoss = 100\n",
    "#sg.epoch, sg.imer, sg.minGEpoch, sg.minGdLoss, sg.startFrom = 0, 0, 0, 1, 0\n",
    "#print(sg.epoch, sg.imer, sg.minGEpoch, sg.minGdLoss, sg.scheduler_D.get_last_lr()[0], sg.startFrom)\n",
    "#lastLR = sg.scheduler_D.get_last_lr()[0]\n",
    "#initialLR = sg.TCfg.learningRateD\n",
    "#print(f\"Initial LR : {lastLR} {lastLR/initialLR:.3f}\")\n",
    "#sg.initialTest()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Execute</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 148/274647 [00:59<30:50:51,  2.47it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'sinogap_module_alt' has no attribute 'scheduler_D'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m sg\u001b[38;5;241m.\u001b[39mnoAdv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m :\n\u001b[0;32m---> 55\u001b[0m     \u001b[43msg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msavedCheckPoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m :\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m sg\u001b[38;5;241m.\u001b[39mdataLoader\n",
      "File \u001b[0;32m~/usr/src/sinogap/sinogap_module_alt.py:1604\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(savedCheckPoint)\u001b[0m\n\u001b[1;32m   1568\u001b[0m \u001b[38;5;66;03m#_,_,_ =  logStep(iter)\u001b[39;00m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;66;03m#collageR, probsR, _ = generateDiffImages(refImages[[0],...], layout=0)\u001b[39;00m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;66;03m#showMe = np.zeros( (2*DCfg.sinoSh[1] + DCfg.gapW ,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;66;03m#addImage(4,0,collageR[0,1])\u001b[39;00m\n\u001b[1;32m   1593\u001b[0m \u001b[38;5;66;03m#addImage(4,1,collageR[0,3], stretch=False)\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalars(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLosses per iter\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1595\u001b[0m                    {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDis\u001b[39m\u001b[38;5;124m'\u001b[39m: trainRes\u001b[38;5;241m.\u001b[39mlossD\n\u001b[1;32m   1596\u001b[0m                    ,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGen\u001b[39m\u001b[38;5;124m'\u001b[39m: trainRes\u001b[38;5;241m.\u001b[39mlossGA\n\u001b[1;32m   1597\u001b[0m                    ,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRec\u001b[39m\u001b[38;5;124m'\u001b[39m: ADV_DIF \u001b[38;5;241m*\u001b[39m trainRes\u001b[38;5;241m.\u001b[39mlossGA \\\n\u001b[1;32m   1598\u001b[0m                            \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mADV_DIF) \u001b[38;5;241m*\u001b[39m trainRes\u001b[38;5;241m.\u001b[39mlossGD \u001b[38;5;241m*\u001b[39m normRec\n\u001b[1;32m   1599\u001b[0m                    }, imer )\n\u001b[1;32m   1600\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalars(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistances per iter\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1601\u001b[0m                    {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSE\u001b[39m\u001b[38;5;124m'\u001b[39m: trainRes\u001b[38;5;241m.\u001b[39mlossMSE\n\u001b[1;32m   1602\u001b[0m                    ,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL1L\u001b[39m\u001b[38;5;124m'\u001b[39m: trainRes\u001b[38;5;241m.\u001b[39mlossL1L\n\u001b[1;32m   1603\u001b[0m                    ,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREC\u001b[39m\u001b[38;5;124m'\u001b[39m: trainRes\u001b[38;5;241m.\u001b[39mlossGD\n\u001b[0;32m-> 1604\u001b[0m                    }, imer )\n\u001b[1;32m   1605\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalars(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProbs per iter\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1606\u001b[0m                    {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRef\u001b[39m\u001b[38;5;124m'\u001b[39m:trainRes\u001b[38;5;241m.\u001b[39mpredReal\n\u001b[1;32m   1607\u001b[0m                    ,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGen\u001b[39m\u001b[38;5;124m'\u001b[39m:trainRes\u001b[38;5;241m.\u001b[39mpredFake\n\u001b[1;32m   1608\u001b[0m                    ,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPre\u001b[39m\u001b[38;5;124m'\u001b[39m:trainRes\u001b[38;5;241m.\u001b[39mpredPre\n\u001b[1;32m   1609\u001b[0m                    }, imer )\n\u001b[1;32m   1611\u001b[0m IPython\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mclear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[16], line 32\u001b[0m, in \u001b[0;36mmy_beforeReport\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmy_beforeReport\u001b[39m() :\n\u001b[0;32m---> 32\u001b[0m     lastLR \u001b[38;5;241m=\u001b[39m \u001b[43msg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler_D\u001b[49m\u001b[38;5;241m.\u001b[39mget_last_lr()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLR : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlastLR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlastLR\u001b[38;5;241m/\u001b[39msg\u001b[38;5;241m.\u001b[39mTCfg\u001b[38;5;241m.\u001b[39mlearningRateD\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lastLR  \u001b[38;5;241m>\u001b[39m  \u001b[38;5;241m0.2\u001b[39m \u001b[38;5;241m*\u001b[39m sg\u001b[38;5;241m.\u001b[39mTCfg\u001b[38;5;241m.\u001b[39mlearningRateD :\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sinogap_module_alt' has no attribute 'scheduler_D'"
     ]
    }
   ],
   "source": [
    "sg.noAdv = True\n",
    "sg.dataLoader = sg.createDataLoader(trainSet, num_workers=16)\n",
    "#sg.testLoader = sg.createDataLoader(testSet , num_workers=16)\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "torch.optim.lr_scheduler.LambdaLR(sg.optimizer_G, lambda epoch: 0.1).step()\n",
    "\n",
    "#\n",
    "#def my_afterEachEpoch(epoch) :\n",
    "#    if sg.minGEpoch < 600 :\n",
    "#        return\n",
    "#    if not sg.dataLoader is None :\n",
    "#        del sg.dataLoader\n",
    "#        sg.freeGPUmem()\n",
    "#    if sg.TCfg.batchSize < 131072 :\n",
    "#    sg.TCfg.batchSize += round( 0.01 * sg.TCfg.batchSize )\n",
    "#    sg.dataLoader = sg.createTrainLoader(trainSet, num_workers=24)\n",
    "#    print(\"Batch size: \",sg.TCfg.batchSize)\n",
    "#sg.afterEachEpoch = my_afterEachEpoch\n",
    "\n",
    "#def my_beforeReport() :\n",
    "#    sg.generator.amplitude = max(4, sg.generator.amplitude * (1-0.0005) )\n",
    "#    print(f\"AMPL : {sg.generator.amplitude}\")\n",
    "#    with open(f\"message_{sg.TCfg.exec}.txt\", 'a') as file:\n",
    "#        file.write(f\"sg.generator.amplitude: {sg.generator.amplitude}\\n\")\n",
    "#    return\n",
    "#sg.beforeReport = my_beforeReport\n",
    "\n",
    "sg.SSIM_MSE = 1\n",
    "sg.ADV_DIF = 0\n",
    "def my_beforeReport() :\n",
    "    lastLR = sg.scheduler_D.get_last_lr()[0]\n",
    "    print(f\"LR : {lastLR} {lastLR/sg.TCfg.learningRateD:.3f}\")\n",
    "    if lastLR  >  0.2 * sg.TCfg.learningRateD :\n",
    "        if sg.scheduler_G is not None :\n",
    "            sg.scheduler_G.step()\n",
    "        if sg.scheduler_D is not None :\n",
    "            sg.scheduler_D.step()\n",
    "    #sg.generator.amplitude = min(4, sg.generator.amplitude * (1+0.0005) )\n",
    "    #print(f\"AMPL : {sg.generator.amplitude}\")\n",
    "    #with open(f\"message_{sg.TCfg.exec}.txt\", 'a') as file:\n",
    "    #    file.write(f\"sg.generator.amplitude: {sg.generator.amplitude}\\n\")\n",
    "    #message = f\" SSIM/MSE : {sg.SSIM_MSE:.3f}\"\n",
    "#    #print(message)\n",
    "#    #if sg.SSIM_MSE < 0.99 :\n",
    "#    #    sg.SSIM_MSE += 1e-3\n",
    "#    #    with open(f\"message_{sg.TCfg.exec}.txt\", 'a') as file:\n",
    "#    #        file.write(message + \"\\n\")\n",
    "    return\n",
    "sg.beforeReport = my_beforeReport\n",
    "\n",
    "sg.noAdv = True\n",
    "\n",
    "try :\n",
    "    sg.train(savedCheckPoint)\n",
    "except :\n",
    "    del sg.dataLoader\n",
    "    #del sg.testLoader\n",
    "    sg.freeGPUmem()\n",
    "    1/10 # to release Jupyuter memory in the next step\n",
    "    sg.epoch -= 1\n",
    "    raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Post</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sg.generator.amplitude.item(), 2 * torch.sigmoid(sg.generator.amplitude).item() )\n",
    "sg.initialTest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.testMe(trainSet, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Save results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.saveModels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
