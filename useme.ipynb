{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Header</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Imports</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import IPython\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fn\n",
    "from torch import optim\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread, imsave\n",
    "import h5py\n",
    "import tifffile\n",
    "import tqdm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Functions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def eprint(*args, **kwargs):\n",
    "    print(*args, file=sys.stderr, **kwargs)\n",
    "\n",
    "\n",
    "def plotData(dataY, rangeY=None, dataYR=None, rangeYR=None,\n",
    "             dataX=None, rangeX=None, rangeP=None,\n",
    "             figsize=(16,8), saveTo=None, show=True):\n",
    "\n",
    "    if type(dataY) is np.ndarray :\n",
    "        plotData((dataY,), rangeY=rangeY, dataYR=dataYR, rangeYR=rangeYR,\n",
    "             dataX=dataX, rangeX=rangeX, rangeP=rangeP,\n",
    "             figsize=figsize, saveTo=saveTo, show=show)\n",
    "        return\n",
    "    if type(dataYR) is np.ndarray :\n",
    "        plotData(dataY, rangeY=rangeY, dataYR=(dataYR,), rangeYR=rangeYR,\n",
    "             dataX=dataX, rangeX=rangeX, rangeP=rangeP,\n",
    "             figsize=figsize, saveTo=saveTo, show=show)\n",
    "        return\n",
    "    if type(dataY) is not tuple :\n",
    "        eprint(f\"Unknown data type to plot: {type(dataY)}.\")\n",
    "        return\n",
    "    if type(dataYR) is not tuple and dataYR is not None:\n",
    "        eprint(f\"Unknown data type to plot: {type(dataYR)}.\")\n",
    "        return\n",
    "\n",
    "    last = min( len(data) for data in dataY )\n",
    "    if dataYR is not None:\n",
    "        last = min( last,  min( len(data) for data in dataYR ) )\n",
    "    if dataX is not None:\n",
    "        last = min(last, len(dataX))\n",
    "    if rangeP is None :\n",
    "        rangeP = (0,last)\n",
    "    elif type(rangeP) is int :\n",
    "        rangeP = (0,rangeP) if rangeP > 0 else (-rangeP,last)\n",
    "    elif type(rangeP) is tuple :\n",
    "        rangeP = ( 0    if rangeP[0] is None else rangeP[0],\n",
    "                   last if rangeP[1] is None else rangeP[1],)\n",
    "    else :\n",
    "        eprint(f\"Bad data type on plotData input rangeP: {type(rangeP)}\")\n",
    "        raise Exception(f\"Bug in the code.\")\n",
    "    rangeP = np.s_[ max(0, rangeP[0]) : min(last, rangeP[1]) ]\n",
    "    if dataX is None :\n",
    "        dataX = np.arange(rangeP.start, rangeP.stop)\n",
    "\n",
    "    plt.style.use('default')\n",
    "    plt.style.use('dark_background')\n",
    "    fig, ax1 = plt.subplots(figsize=figsize)\n",
    "    ax1.xaxis.grid(True, 'both', linestyle='dotted')\n",
    "    if rangeX is not None :\n",
    "        ax1.set_xlim(rangeX)\n",
    "    else :\n",
    "        ax1.set_xlim(rangeP.start,rangeP.stop-1)\n",
    "\n",
    "    ax1.yaxis.grid(True, 'both', linestyle='dotted')\n",
    "    nofPlots = len(dataY)\n",
    "    if rangeY is not None:\n",
    "        ax1.set_ylim(rangeY)\n",
    "    colors = [ matplotlib.colors.hsv_to_rgb((hv/nofPlots, 1, 1)) for hv in range(nofPlots) ]\n",
    "    for idx , data in enumerate(dataY):\n",
    "        ax1.plot(dataX, data[rangeP], linestyle='-',  color=colors[idx])\n",
    "\n",
    "    if dataYR is not None : # right Y axis\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.yaxis.grid(True, 'both', linestyle='dotted')\n",
    "        nofPlots = len(dataYR)\n",
    "        if rangeYR is not None:\n",
    "            ax2.set_ylim(rangeYR)\n",
    "        colors = [ matplotlib.colors.hsv_to_rgb((hv/nofPlots, 1, 1)) for hv in range(nofPlots) ]\n",
    "        for idx , data in enumerate(dataYR):\n",
    "            ax2.plot(dataX, data[rangeP], linestyle='dashed',  color=colors[idx])\n",
    "\n",
    "    if saveTo:\n",
    "        fig.savefig(saveTo)\n",
    "    if not show:\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "def plotImage(image) :\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plotImages(images) :\n",
    "    for i, img in enumerate(images) :\n",
    "        ax = plt.subplot(1, len(images), i + 1)\n",
    "        plt.imshow(img.squeeze(), cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def tensorStat(stat) :\n",
    "    print(f\"{stat.mean().item():.3e}, {stat.std().item():.3e}, \"\n",
    "          f\"{stat.min().item():.3e}, {stat.max().item():.3e}\")\n",
    "\n",
    "\n",
    "def fillWheights(seq) :\n",
    "    for wh in seq :\n",
    "        if hasattr(wh, 'weight') :\n",
    "            torch.nn.init.xavier_uniform_(wh.weight)\n",
    "            #torch.nn.init.zeros_(wh.weight)\n",
    "            #torch.nn.init.constant_(wh.weight, 0)\n",
    "            #torch.nn.init.uniform_(wh.weight, a=0.0, b=1.0, generator=None)\n",
    "            #torch.nn.init.normal_(wh.weight, mean=0.0, std=0.01)\n",
    "\n",
    "\n",
    "def unsqeeze4dim(tens):\n",
    "    orgDims = tens.dim()\n",
    "    if tens.dim() == 2 :\n",
    "        tens = tens.unsqueeze(0)\n",
    "    if tens.dim() == 3 :\n",
    "        tens = tens.unsqueeze(1)\n",
    "    return tens, orgDims\n",
    "\n",
    "\n",
    "def squeezeOrg(tens, orgDims):\n",
    "    if orgDims == tens.dim():\n",
    "        return tens\n",
    "    if tens.dim() != 4 or orgDims > 4 or orgDims < 2:\n",
    "        raise Exception(f\"Unexpected dimensions to squeeze: {tens.dim()} {orgDims}.\")\n",
    "    if orgDims < 4 :\n",
    "        if tens.shape[1] > 1:\n",
    "            raise Exception(f\"Cant squeeze dimension 1 in: {tens.shape}.\")\n",
    "        tens = tens.squeeze(1)\n",
    "    if orgDims < 3 :\n",
    "        if tens.shape[0] > 1:\n",
    "            raise Exception(f\"Cant squeeze dimension 0 in: {tens.shape}.\")\n",
    "        tens = tens.squeeze(0)\n",
    "    return tens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Configs</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(SEED_VALUE):\n",
    "    torch.manual_seed(SEED_VALUE)\n",
    "    torch.cuda.manual_seed(SEED_VALUE)\n",
    "    torch.cuda.manual_seed_all(SEED_VALUE)\n",
    "    np.random.seed(SEED_VALUE)\n",
    "\n",
    "seed = 7\n",
    "set_seed(seed)\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TCfg:\n",
    "    exec = 1\n",
    "    device: torch.device = f\"cuda:{exec}\"\n",
    "    latentDim: int = 64\n",
    "\n",
    "class DCfg:\n",
    "    gapW = 16\n",
    "    sinoSh = (5*gapW,5*gapW) # 80x80\n",
    "    readSh = (80, 80)\n",
    "    sinoSize = math.prod(sinoSh)\n",
    "    gapSh = (sinoSh[0],gapW)\n",
    "    gapSize = math.prod(gapSh)\n",
    "    gapRngX = np.s_[ sinoSh[1]//2 - gapW//2 : sinoSh[1]//2 + gapW//2 ]\n",
    "    gapRng = np.s_[ : , gapRngX ]\n",
    "    disRng = np.s_[ gapW:-gapW , gapRngX ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Save/Load</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, model_path):\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    return model\n",
    "\n",
    "\n",
    "def addToHDF(filename, containername, data) :\n",
    "    if len(data.shape) == 2 :\n",
    "        data=np.expand_dims(data, 0)\n",
    "    if len(data.shape) != 3 :\n",
    "        raise Exception(f\"Not appropriate input array size {data.shape}.\")\n",
    "\n",
    "    with h5py.File(filename,'a') as file :\n",
    "\n",
    "        if  containername not in file.keys():\n",
    "            dset = file.create_dataset(containername, data.shape,\n",
    "                                       maxshape=(None,data.shape[1],data.shape[2]),\n",
    "                                       dtype='f')\n",
    "            dset[()] = data\n",
    "            return\n",
    "\n",
    "        dset = file[containername]\n",
    "        csh = dset.shape\n",
    "        if csh[1] != data.shape[1] or csh[2] != data.shape[2] :\n",
    "            raise Exception(f\"Shape mismatch: input {data.shape}, file {dset.shape}.\")\n",
    "        msh = dset.maxshape\n",
    "        newLen = csh[0] + data.shape[0]\n",
    "        if msh[0] is None or msh[0] >= newLen :\n",
    "            dset.resize(newLen, axis=0)\n",
    "        else :\n",
    "            raise Exception(f\"Insufficient maximum shape {msh} to add data\"\n",
    "                            f\" {data.shape} to current volume {dset.shape}.\")\n",
    "        dset[csh[0]:newLen,...] = data\n",
    "        file.close()\n",
    "\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Raw Read</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getInData(inputString):\n",
    "    sampleHDF = inputString.split(':')\n",
    "    if len(sampleHDF) != 2 :\n",
    "        raise Exception(f\"String \\\"{inputString}\\\" does not represent an HDF5 format \\\"fileName:container\\\".\")\n",
    "    try :\n",
    "        trgH5F =  h5py.File(sampleHDF[0],'r')\n",
    "    except :\n",
    "        raise Exception(f\"Failed to open HDF file '{sampleHDF[0]}'.\")\n",
    "    if  sampleHDF[1] not in trgH5F.keys():\n",
    "        raise Exception(f\"No dataset '{sampleHDF[1]}' in input file {sampleHDF[0]}.\")\n",
    "    data = trgH5F[sampleHDF[1]]\n",
    "    if not data.size :\n",
    "        raise Exception(f\"Container \\\"{inputString}\\\" is zero size.\")\n",
    "    sh = data.shape\n",
    "    if len(sh) != 3 :\n",
    "        raise Exception(f\"Dimensions of the container \\\"{inputString}\\\" is not 3: {sh}.\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def getOutData(outputString, shape) :\n",
    "    if len(shape) == 2 :\n",
    "        shape = (1,*shape)\n",
    "    if len(shape) != 3 :\n",
    "        raise Exception(f\"Not appropriate output array size {shape}.\")\n",
    "\n",
    "    sampleHDF = outputString.split(':')\n",
    "    if len(sampleHDF) != 2 :\n",
    "        raise Exception(f\"String \\\"{outputString}\\\" does not represent an HDF5 format \\\"fileName:container\\\".\")\n",
    "    try :\n",
    "        trgH5F =  h5py.File(sampleHDF[0],'w')\n",
    "    except :\n",
    "        raise Exception(f\"Failed to open HDF file '{sampleHDF[0]}'.\")\n",
    "\n",
    "    if  sampleHDF[1] not in trgH5F.keys():\n",
    "        dset = trgH5F.create_dataset(sampleHDF[1], shape, dtype='f')\n",
    "    else :\n",
    "        dset = trgH5F[sampleHDF[1]]\n",
    "        csh = dset.shape\n",
    "        if csh[0] < shape[0] or csh[1] != shape[1] or csh[2] != shape[2] :\n",
    "            raise Exception(f\"Shape mismatch: input {shape}, file {dset.shape}.\")\n",
    "    return dset, trgH5F\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "source": [
    "## <font style=\"color:lightblue\">Models</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Lower resolution generators</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font style=\"color:lightblue\">Two pixels gap</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2863764/1559722796.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generator2(\n",
       "  (noise2latent): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=700, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Unflatten(dim=1, unflattened_size=(7, 10, 10))\n",
       "  )\n",
       "  (encode): Sequential(\n",
       "    (0): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.2)\n",
       "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (5): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (link): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "    (3): Unflatten(dim=1, unflattened_size=torch.Size([64, 4, 4]))\n",
       "  )\n",
       "  (decode): Sequential(\n",
       "    (0): ConvTranspose2d(64, 64, kernel_size=(3, 1), stride=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): ConvTranspose2d(64, 64, kernel_size=(3, 1), stride=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.2)\n",
       "    (4): ConvTranspose2d(64, 64, kernel_size=(3, 1), stride=(1, 1))\n",
       "    (5): LeakyReLU(negative_slope=0.2)\n",
       "    (6): Conv2d(64, 1, kernel_size=(1, 3), stride=(1, 1))\n",
       "    (7): Tanh()\n",
       "  )\n",
       "  (body): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (3): LeakyReLU(negative_slope=0.2)\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (5): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "      (3): Unflatten(dim=1, unflattened_size=torch.Size([64, 4, 4]))\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(64, 64, kernel_size=(3, 1), stride=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "      (2): ConvTranspose2d(64, 64, kernel_size=(3, 1), stride=(1, 1))\n",
       "      (3): LeakyReLU(negative_slope=0.2)\n",
       "      (4): ConvTranspose2d(64, 64, kernel_size=(3, 1), stride=(1, 1))\n",
       "      (5): LeakyReLU(negative_slope=0.2)\n",
       "      (6): Conv2d(64, 1, kernel_size=(1, 3), stride=(1, 1))\n",
       "      (7): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Generator2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator2, self).__init__()\n",
    "\n",
    "        self.gapW = 2\n",
    "        self.sinoSh = (5*self.gapW,5*self.gapW) # 10,10\n",
    "        self.sinoSize = math.prod(self.sinoSh)\n",
    "        self.gapSh = (self.sinoSh[0],self.gapW)\n",
    "        self.gapSize = math.prod(self.gapSh)\n",
    "        self.gapRngX = np.s_[ self.sinoSh[1]//2 - self.gapW//2 : self.sinoSh[1]//2 + self.gapW//2 ]\n",
    "        self.gapRng = np.s_[ : , self.gapRngX ]\n",
    "\n",
    "        latentChannels = 7\n",
    "        self.noise2latent = nn.Sequential(\n",
    "            nn.Linear(TCfg.latentDim, self.sinoSize*latentChannels),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten( 1, (latentChannels,) + self.sinoSh )\n",
    "        )\n",
    "        fillWheights(self.noise2latent)\n",
    "\n",
    "        baseChannels = 64\n",
    "\n",
    "        self.encode = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(latentChannels+1, baseChannels, 3),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(baseChannels, baseChannels, 3),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(baseChannels, baseChannels, 3),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "        )\n",
    "        fillWheights(self.encode)\n",
    "\n",
    "        encSh = self.encode(torch.zeros((1,latentChannels+1,*self.sinoSh))).shape\n",
    "        linChannels = math.prod(encSh)\n",
    "        self.link = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(linChannels, linChannels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Unflatten(1, encSh[1:]),\n",
    "        )\n",
    "        fillWheights(self.link)\n",
    "\n",
    "\n",
    "        self.decode = nn.Sequential(\n",
    "\n",
    "            nn.ConvTranspose2d(baseChannels, baseChannels, (3,1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.ConvTranspose2d(baseChannels, baseChannels, (3,1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.ConvTranspose2d(baseChannels, baseChannels, (3,1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(baseChannels, 1, (1,3)),\n",
    "            nn.Tanh()\n",
    "\n",
    "        )\n",
    "        fillWheights(self.decode)\n",
    "\n",
    "\n",
    "        self.body = nn.Sequential(\n",
    "            self.encode,\n",
    "            self.link,\n",
    "            self.decode\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        images, noises = input\n",
    "        images, orgDims = unsqeeze4dim(images)\n",
    "        latent = self.noise2latent(noises)\n",
    "        modelIn = torch.cat((images,latent),dim=1)\n",
    "        mIn = modelIn[:,0,*self.gapRng]\n",
    "        mIn[()] = self.preProc(images[:,0,:,:])\n",
    "        patches = self.body(modelIn)\n",
    "        mIn = mIn.unsqueeze(1)\n",
    "        #patches = mIn + torch.where( patches < 0 , patches * mIn , patches ) # no normalization\n",
    "        patches = mIn + patches * torch.where( patches < 0 , mIn+0.5 , 1 ) # normalization\n",
    "        return squeezeOrg(patches, orgDims)\n",
    "\n",
    "\n",
    "    def preProc(self, images) :\n",
    "        images = images.unsqueeze(0) # for the 2D case\n",
    "        res = torch.zeros(images[...,*self.gapRng].shape, device=images.device)\n",
    "        res[...,0] += 2*images[...,self.gapRngX.start-1] + images[...,self.gapRngX.stop]\n",
    "        res[...,1] += 2*images[...,self.gapRngX.stop] + images[...,self.gapRngX.start-1]\n",
    "        res = res.squeeze(0) # to compensate for the first squeeze\n",
    "        return res/3\n",
    "\n",
    "    def generatePatches(self, images, noises=None) :\n",
    "        if noises is None :\n",
    "            noises = torch.randn( 1 if images.dim() < 3 else images.shape[0], TCfg.latentDim).to(TCfg.device)\n",
    "        return self.forward((images,noises))\n",
    "\n",
    "\n",
    "    def fillImages(self, images, noises=None) :\n",
    "        images[...,*self.gapRng] = self.generatePatches(images, noises)\n",
    "        return images\n",
    "\n",
    "\n",
    "    def generateImages(self, images, noises=None) :\n",
    "        clone = images.clone()\n",
    "        return self.fillImages(clone, noises)\n",
    "\n",
    "\n",
    "generator2 = Generator2()\n",
    "generator2 = load_model(generator2, model_path=\"saves/gap2_cor.model_gen.pt\" )\n",
    "generator2.to(TCfg.device)\n",
    "generator2.requires_grad_(False)\n",
    "generator2.eval()\n",
    "#model_summary = summary(generator2, input_data=[ [refImages, refNoises] ] ).__str__()\n",
    "#print(model_summary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font style=\"color:lightblue\">Four pixels gap</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2863764/1559722796.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generator4(\n",
       "  (noise2latent): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=2800, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Unflatten(dim=1, unflattened_size=(7, 20, 20))\n",
       "  )\n",
       "  (encode): Sequential(\n",
       "    (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (3): LeakyReLU(negative_slope=0.2)\n",
       "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (5): LeakyReLU(negative_slope=0.2)\n",
       "    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (link): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "    (3): Unflatten(dim=1, unflattened_size=torch.Size([128, 4, 4]))\n",
       "  )\n",
       "  (decode): Sequential(\n",
       "    (0): ConvTranspose2d(128, 128, kernel_size=(3, 1), stride=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): ConvTranspose2d(128, 128, kernel_size=(3, 1), stride=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.2)\n",
       "    (4): ConvTranspose2d(128, 128, kernel_size=(4, 1), stride=(2, 1))\n",
       "    (5): LeakyReLU(negative_slope=0.2)\n",
       "    (6): ConvTranspose2d(128, 128, kernel_size=(3, 1), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.2)\n",
       "    (8): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (9): Tanh()\n",
       "  )\n",
       "  (body): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (3): LeakyReLU(negative_slope=0.2)\n",
       "      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (5): LeakyReLU(negative_slope=0.2)\n",
       "      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (7): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "      (3): Unflatten(dim=1, unflattened_size=torch.Size([128, 4, 4]))\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(128, 128, kernel_size=(3, 1), stride=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "      (2): ConvTranspose2d(128, 128, kernel_size=(3, 1), stride=(1, 1))\n",
       "      (3): LeakyReLU(negative_slope=0.2)\n",
       "      (4): ConvTranspose2d(128, 128, kernel_size=(4, 1), stride=(2, 1))\n",
       "      (5): LeakyReLU(negative_slope=0.2)\n",
       "      (6): ConvTranspose2d(128, 128, kernel_size=(3, 1), stride=(1, 1))\n",
       "      (7): LeakyReLU(negative_slope=0.2)\n",
       "      (8): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (9): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Generator4(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator4, self).__init__()\n",
    "\n",
    "        self.gapW = 4\n",
    "        self.sinoSh = (5*self.gapW,5*self.gapW) # 20,20\n",
    "        self.sinoSize = math.prod(self.sinoSh)\n",
    "        self.gapSh = (self.sinoSh[0],self.gapW)\n",
    "        self.gapSize = math.prod(self.gapSh)\n",
    "        self.gapRngX = np.s_[ self.sinoSh[1]//2 - self.gapW//2 : self.sinoSh[1]//2 + self.gapW//2 ]\n",
    "        self.gapRng = np.s_[ : , self.gapRngX ]\n",
    "\n",
    "        latentChannels = 7\n",
    "        self.noise2latent = nn.Sequential(\n",
    "            nn.Linear(TCfg.latentDim, self.sinoSize*latentChannels),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten( 1, (latentChannels,) + self.sinoSh )\n",
    "        )\n",
    "        fillWheights(self.noise2latent)\n",
    "\n",
    "        baseChannels = 128\n",
    "\n",
    "        self.encode = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(latentChannels+1, baseChannels, 3),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(baseChannels, baseChannels, 3, stride=2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(baseChannels, baseChannels, 3),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(baseChannels, baseChannels, 3),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "        )\n",
    "        fillWheights(self.encode)\n",
    "\n",
    "\n",
    "        encSh = self.encode(torch.zeros((1,latentChannels+1,*self.sinoSh))).shape\n",
    "        linChannels = math.prod(encSh)\n",
    "        self.link = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(linChannels, linChannels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Unflatten(1, encSh[1:]),\n",
    "        )\n",
    "        fillWheights(self.link)\n",
    "\n",
    "\n",
    "        self.decode = nn.Sequential(\n",
    "\n",
    "            nn.ConvTranspose2d(baseChannels, baseChannels, (3,1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.ConvTranspose2d(baseChannels, baseChannels, (3,1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.ConvTranspose2d(baseChannels, baseChannels, (4,1), stride=(2,1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.ConvTranspose2d(baseChannels, baseChannels, (3,1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(baseChannels, 1, 1),\n",
    "            nn.Tanh()\n",
    "\n",
    "        )\n",
    "        fillWheights(self.decode)\n",
    "\n",
    "\n",
    "        self.body = nn.Sequential(\n",
    "            self.encode,\n",
    "            self.link,\n",
    "            self.decode\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        images, noises = input\n",
    "        images, orgDims = unsqeeze4dim(images)\n",
    "        latent = self.noise2latent(noises)\n",
    "        modelIn = torch.cat((images,latent),dim=1)\n",
    "        mIn = modelIn[:,0,*self.gapRng]\n",
    "        mIn[()] = self.preProc(images[:,0,:,:])\n",
    "        patches = self.body(modelIn)\n",
    "        mIn = mIn.unsqueeze(1)\n",
    "        #patches = mIn + torch.where( patches < 0 , patches * mIn , patches ) # no normalization\n",
    "        patches = mIn + patches * torch.where( patches < 0 , mIn+0.5 , 1 ) # normalization\n",
    "        return squeezeOrg(patches, orgDims)\n",
    "\n",
    "\n",
    "    def preProc(self, images) :\n",
    "        images, orgDims = unsqeeze4dim(images)\n",
    "        preImages = torch.nn.functional.interpolate(images, scale_factor=0.5, mode='area')\n",
    "        prePatches = generator2.generatePatches(preImages)\n",
    "        prePatches = torch.nn.functional.interpolate(prePatches, scale_factor=2, mode='bilinear')\n",
    "        return squeezeOrg(prePatches, orgDims)\n",
    "\n",
    "\n",
    "    def generatePatches(self, images, noises=None) :\n",
    "        if noises is None :\n",
    "            noises = torch.randn( 1 if images.dim() < 3 else images.shape[0], TCfg.latentDim).to(TCfg.device)\n",
    "        return self.forward((images,noises))\n",
    "\n",
    "\n",
    "    def fillImages(self, images, noises=None) :\n",
    "        images[...,*self.gapRng] = self.generatePatches(images, noises)\n",
    "        return images\n",
    "\n",
    "\n",
    "    def generateImages(self, images, noises=None) :\n",
    "        clone = images.clone()\n",
    "        return self.fillImages(clone, noises)\n",
    "\n",
    "\n",
    "generator4 = Generator4()\n",
    "generator4 = load_model(generator4, model_path=\"saves/gap4_cor.model_gen.pt\" )\n",
    "generator4.to(TCfg.device)\n",
    "generator4.requires_grad_(False)\n",
    "generator4.eval()\n",
    "#model_summary = summary(generator4, input_data=[ [refImages, refNoises] ] ).__str__()\n",
    "#print(model_summary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font style=\"color:lightblue\">Eight pixels gap</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2863764/1559722796.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generator8(\n",
       "  (noise2latent): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=11200, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Unflatten(dim=1, unflattened_size=(7, 40, 40))\n",
       "  )\n",
       "  (encode): Sequential(\n",
       "    (0): Conv2d(8, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (3): LeakyReLU(negative_slope=0.2)\n",
       "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (5): LeakyReLU(negative_slope=0.2)\n",
       "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (9): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (link): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "    (3): Unflatten(dim=1, unflattened_size=torch.Size([256, 4, 4]))\n",
       "  )\n",
       "  (decode): Sequential(\n",
       "    (0): ConvTranspose2d(256, 256, kernel_size=(3, 1), stride=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): ConvTranspose2d(256, 256, kernel_size=(3, 1), stride=(1, 1), bias=False)\n",
       "    (3): LeakyReLU(negative_slope=0.2)\n",
       "    (4): ConvTranspose2d(256, 256, kernel_size=(4, 1), stride=(2, 1), bias=False)\n",
       "    (5): LeakyReLU(negative_slope=0.2)\n",
       "    (6): ConvTranspose2d(256, 256, kernel_size=(4, 3), stride=(2, 1), bias=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2)\n",
       "    (8): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (9): LeakyReLU(negative_slope=0.2)\n",
       "    (10): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (11): Tanh()\n",
       "  )\n",
       "  (body): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(8, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (3): LeakyReLU(negative_slope=0.2)\n",
       "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (5): LeakyReLU(negative_slope=0.2)\n",
       "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (7): LeakyReLU(negative_slope=0.2)\n",
       "      (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (9): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "      (3): Unflatten(dim=1, unflattened_size=torch.Size([256, 4, 4]))\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(256, 256, kernel_size=(3, 1), stride=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "      (2): ConvTranspose2d(256, 256, kernel_size=(3, 1), stride=(1, 1), bias=False)\n",
       "      (3): LeakyReLU(negative_slope=0.2)\n",
       "      (4): ConvTranspose2d(256, 256, kernel_size=(4, 1), stride=(2, 1), bias=False)\n",
       "      (5): LeakyReLU(negative_slope=0.2)\n",
       "      (6): ConvTranspose2d(256, 256, kernel_size=(4, 3), stride=(2, 1), bias=False)\n",
       "      (7): LeakyReLU(negative_slope=0.2)\n",
       "      (8): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (9): LeakyReLU(negative_slope=0.2)\n",
       "      (10): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (11): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Generator8(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator8, self).__init__()\n",
    "\n",
    "        self.gapW = 8\n",
    "        self.sinoSh = (5*self.gapW,5*self.gapW) # 20,20\n",
    "        self.sinoSize = math.prod(self.sinoSh)\n",
    "        self.gapSh = (self.sinoSh[0],self.gapW)\n",
    "        self.gapSize = math.prod(self.gapSh)\n",
    "        self.gapRngX = np.s_[ self.sinoSh[1]//2 - self.gapW//2 : self.sinoSh[1]//2 + self.gapW//2 ]\n",
    "        self.gapRng = np.s_[ : , self.gapRngX ]\n",
    "\n",
    "        latentChannels = 7\n",
    "        self.noise2latent = nn.Sequential(\n",
    "            nn.Linear(TCfg.latentDim, self.sinoSize*latentChannels),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten( 1, (latentChannels,) + self.sinoSh )\n",
    "        )\n",
    "        fillWheights(self.noise2latent)\n",
    "\n",
    "        baseChannels = 256\n",
    "\n",
    "        self.encode = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(latentChannels+1, baseChannels, 3, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(baseChannels, baseChannels, 3, stride=2, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(baseChannels, baseChannels, 3, stride=2, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(baseChannels, baseChannels, 3, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(baseChannels, baseChannels, 3, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "\n",
    "        )\n",
    "        fillWheights(self.encode)\n",
    "\n",
    "\n",
    "        encSh = self.encode(torch.zeros((1,latentChannels+1,*self.sinoSh))).shape\n",
    "        linChannels = math.prod(encSh)\n",
    "        self.link = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(linChannels, linChannels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Unflatten(1, encSh[1:]),\n",
    "        )\n",
    "        fillWheights(self.link)\n",
    "\n",
    "\n",
    "        self.decode = nn.Sequential(\n",
    "\n",
    "            nn.ConvTranspose2d(baseChannels, baseChannels, (3,1), bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.ConvTranspose2d(baseChannels, baseChannels, (3,1), bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.ConvTranspose2d(baseChannels, baseChannels, (4,1), stride=(2,1), bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.ConvTranspose2d(baseChannels, baseChannels, (4,3), stride=(2,1), bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.ConvTranspose2d(baseChannels, baseChannels, (3,3), bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(baseChannels, 1, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "\n",
    "        )\n",
    "        fillWheights(self.decode)\n",
    "\n",
    "\n",
    "        self.body = nn.Sequential(\n",
    "            self.encode,\n",
    "            self.link,\n",
    "            self.decode\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        images, noises = input\n",
    "        images, orgDims = unsqeeze4dim(images)\n",
    "        latent = self.noise2latent(noises)\n",
    "        modelIn = torch.cat((images,latent),dim=1)\n",
    "        mIn = modelIn[:,0,*self.gapRng]\n",
    "        mIn[()] = self.preProc(images[:,0,:,:])\n",
    "        patches = self.body(modelIn)\n",
    "        #return patches\n",
    "        mIn = mIn.unsqueeze(1)\n",
    "        #patches = mIn + torch.where( patches < 0 , patches * mIn , patches ) # no normalization\n",
    "        patches = mIn + patches * torch.where( patches < 0 , mIn+0.5 , 1 ) # normalization\n",
    "        return squeezeOrg(patches, orgDims)\n",
    "\n",
    "\n",
    "    def preProc(self, images) :\n",
    "        images, orgDims = unsqeeze4dim(images)\n",
    "        preImages = torch.nn.functional.interpolate(images, scale_factor=0.5, mode='area')\n",
    "        prePatches = generator4.generatePatches(preImages)\n",
    "        prePatches = torch.nn.functional.interpolate(prePatches, scale_factor=2, mode='bilinear')\n",
    "        return squeezeOrg(prePatches, orgDims)\n",
    "\n",
    "\n",
    "    def generatePatches(self, images, noises=None) :\n",
    "        if noises is None :\n",
    "            noises = torch.randn( 1 if images.dim() < 3 else images.shape[0], TCfg.latentDim).to(TCfg.device)\n",
    "        return self.forward((images,noises))\n",
    "\n",
    "\n",
    "    def fillImages(self, images, noises=None) :\n",
    "        images[...,*self.gapRng] = self.generatePatches(images, noises)\n",
    "        return images\n",
    "\n",
    "\n",
    "    def generateImages(self, images, noises=None) :\n",
    "        clone = images.clone()\n",
    "        return self.fillImages(clone, noises)\n",
    "\n",
    "\n",
    "generator8 = Generator8()\n",
    "generator8 = load_model(generator8, model_path=\"saves/gap8_cor.model_gen.pt\" )\n",
    "generator8.to(TCfg.device)\n",
    "generator8.requires_grad_(False)\n",
    "generator8.eval()\n",
    "#model_summary = summary(generator8, input_data=[ [refImages, refNoises] ] ).__str__()\n",
    "#print(model_summary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Generator</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2863764/1559722796.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.gapW = DCfg.gapW\n",
    "        self.sinoSh = (5*self.gapW,5*self.gapW) # 80,80\n",
    "        self.sinoSize = math.prod(self.sinoSh)\n",
    "        self.gapSh = (self.sinoSh[0],self.gapW)\n",
    "        self.gapSize = math.prod(self.gapSh)\n",
    "        self.gapRngX = np.s_[ self.sinoSh[1]//2 - self.gapW//2 : self.sinoSh[1]//2 + self.gapW//2 ]\n",
    "        self.gapRng = np.s_[ : , self.gapRngX ]\n",
    "\n",
    "        latentChannels = 7\n",
    "        self.noise2latent = nn.Sequential(\n",
    "            nn.Linear(TCfg.latentDim, self.sinoSize*latentChannels),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten( 1, (latentChannels,) + self.sinoSh )\n",
    "        )\n",
    "        fillWheights(self.noise2latent)\n",
    "\n",
    "        baseChannels = 64\n",
    "\n",
    "\n",
    "        def encblock(chIn, chOut, kernel, stride=1) :\n",
    "            return nn.Sequential (\n",
    "                nn.Conv2d(chIn, chOut, kernel, stride=stride, bias=True),\n",
    "                #nn.BatchNorm2d(chOut),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                #nn.ReLU(),\n",
    "            )\n",
    "        self.encode = nn.Sequential(\n",
    "            encblock(  latentChannels+1,   baseChannels, 3),\n",
    "            encblock(  baseChannels,     2*baseChannels, 3, stride=2),\n",
    "            encblock(2*baseChannels,     2*baseChannels, 3),\n",
    "            encblock(2*baseChannels,     2*baseChannels, 3),\n",
    "            encblock(2*baseChannels,     4*baseChannels, 3, stride=2),\n",
    "            encblock(4*baseChannels,     4*baseChannels, 3),\n",
    "            encblock(4*baseChannels,     8*baseChannels, 3, stride=2),\n",
    "            encblock(8*baseChannels,     8*baseChannels, 3),\n",
    "        )\n",
    "        fillWheights(self.encode)\n",
    "\n",
    "\n",
    "        encSh = self.encode(torch.zeros((1,latentChannels+1,*self.sinoSh))).shape\n",
    "        linChannels = math.prod(encSh)\n",
    "        self.link = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(linChannels, linChannels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Unflatten(1, encSh[1:]),\n",
    "        )\n",
    "        fillWheights(self.link)\n",
    "\n",
    "        def decblock(chIn, chOut, kernel, stride=1) :\n",
    "            return nn.Sequential (\n",
    "                nn.ConvTranspose2d(chIn, chOut, kernel, stride, bias=False),\n",
    "                #nn.BatchNorm2d(chOut),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                #nn.ReLU(),\n",
    "            )\n",
    "        self.decode = nn.Sequential(\n",
    "            decblock(8*baseChannels, 8*baseChannels, 3),\n",
    "            decblock(8*baseChannels, 4*baseChannels, 4, stride=2),\n",
    "            decblock(4*baseChannels, 4*baseChannels, 3),\n",
    "            decblock(4*baseChannels, 2*baseChannels, 4, stride=2),\n",
    "            decblock(2*baseChannels, 2*baseChannels, 3),\n",
    "            decblock(2*baseChannels, 2*baseChannels, 3),\n",
    "            decblock(2*baseChannels,   baseChannels, 4, stride=2),\n",
    "            decblock(baseChannels, baseChannels, 3),\n",
    "\n",
    "            nn.Conv2d(baseChannels, 1, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        fillWheights(self.decode)\n",
    "\n",
    "\n",
    "        self.body = nn.Sequential(\n",
    "            self.encode,\n",
    "            self.link,\n",
    "            self.decode\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        images, noises = input\n",
    "        images, orgDims = unsqeeze4dim(images)\n",
    "        latent = self.noise2latent(noises)\n",
    "        modelIn = torch.cat((images,latent),dim=1)\n",
    "        mIn = modelIn[:,0,*self.gapRng]\n",
    "        mIn[()] = self.preProc(images[:,0,:,:])\n",
    "        patches = self.body(modelIn)[...,self.gapRngX]\n",
    "        #return patches\n",
    "        mIn = mIn.unsqueeze(1)\n",
    "        patches = mIn + patches * torch.where( patches < 0 , mIn+0.5 , 1 ) # normalization\n",
    "        return squeezeOrg(patches, orgDims)\n",
    "\n",
    "\n",
    "    def preProc(self, images) :\n",
    "        images, orgDims = unsqeeze4dim(images)\n",
    "        preImages = torch.nn.functional.interpolate(images, scale_factor=0.5, mode='area')\n",
    "        prePatches = generator8.generatePatches(preImages)\n",
    "        prePatches = torch.nn.functional.interpolate(prePatches, scale_factor=2, mode='bilinear')\n",
    "        return squeezeOrg(prePatches, orgDims)\n",
    "\n",
    "\n",
    "    def generatePatches(self, images, noises=None) :\n",
    "        if noises is None :\n",
    "            noises = torch.randn( 1 if images.dim() < 3 else images.shape[0], TCfg.latentDim).to(TCfg.device)\n",
    "        return self.forward((images,noises))\n",
    "\n",
    "\n",
    "    def fillImages(self, images, noises=None) :\n",
    "        images[...,*self.gapRng] = self.generatePatches(images, noises)\n",
    "        return images\n",
    "\n",
    "\n",
    "    def generateImages(self, images, noises=None) :\n",
    "        clone = images.clone()\n",
    "        return self.fillImages(clone, noises)\n",
    "\n",
    "\n",
    "\n",
    "generator = Generator()\n",
    "generator = load_model(generator, model_path=\"model_1_gen.pt\" )\n",
    "generator = generator.to(TCfg.device)\n",
    "generator = generator.requires_grad_(False)\n",
    "generator = generator.eval()\n",
    "#model_summary = summary(generator, input_data=[ [refImages, refNoises] ] ).__str__()\n",
    "#print(model_summary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Fill sinogram</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fillSinogram(sinogram) :\n",
    "\n",
    "    sinoW = sinogram.shape[-1]\n",
    "    sinoL = sinogram.shape[-2]\n",
    "    if sinoW % 5 :\n",
    "        raise Exception(f\"Sinogram width {sinoW} is not devisable bny 5.\")\n",
    "    blockW = sinoW // 5\n",
    "    sinogram, _ = unsqeeze4dim(sinogram)\n",
    "    sinogram = sinogram.to(TCfg.device)\n",
    "    resizedSino = torch.zeros(( 1 , 1 , sinoL , DCfg.sinoSh[1] ), device=TCfg.device)\n",
    "    resizedSino[ ... , : 2*DCfg.gapW ] = torch.nn.functional.interpolate(\n",
    "        sinogram[ ... , : 2*blockW ], size=( sinoL , 2*DCfg.gapW ), mode='bilinear')\n",
    "    resizedSino[ ... , 2*DCfg.gapW : 3*DCfg.gapW ] = torch.nn.functional.interpolate(\n",
    "        sinogram[ ... , : 2*blockW : 3*blockW ], size=( sinoL , DCfg.gapW ), mode='bilinear')\n",
    "    resizedSino[ ... , 3*DCfg.gapW:] = torch.nn.functional.interpolate(\n",
    "        sinogram[ ... , 3*blockW : ], size=( sinoL , 2*DCfg.gapW ), mode='bilinear')\n",
    "\n",
    "    blockH = DCfg.sinoSh[0]\n",
    "    sinoCutStep = DCfg.gapW\n",
    "    lastStart = sinoL - blockH\n",
    "    nofBlocks, lastBlock = divmod(lastStart, sinoCutStep)\n",
    "    modelIn = torch.empty( ( nofBlocks + bool(lastBlock) , 1 , *DCfg.sinoSh ), device=TCfg.device )\n",
    "    for block in range(nofBlocks) :\n",
    "        modelIn[ block, 0, ... ] = resizedSino[0 , 0, block * sinoCutStep : block * sinoCutStep + blockH , : ]\n",
    "    if lastBlock :\n",
    "        modelIn[ -1, 0, ... ] = resizedSino[0,0, -blockH : , : ]\n",
    "\n",
    "    mytransforms = transforms.Compose([\n",
    "        transforms.Normalize(mean=(0.5), std=(1))\n",
    "    ])\n",
    "    modelIn = mytransforms(modelIn)\n",
    "\n",
    "    modelIn[ -1, 0, ... ] = modelIn[ -1, 0, ... ].flip(dims=(-2,)) # to get rid of the deffect in the end\n",
    "    results = None\n",
    "    with torch.no_grad() :\n",
    "        results = generator.generatePatches(modelIn)\n",
    "    results[ -1, 0, ... ] = results[ -1, 0, ... ].flip(dims=(-2,)) # to flip back\n",
    "\n",
    "    if lastBlock :\n",
    "        newLast = torch.zeros(DCfg.gapSh, device=TCfg.device)\n",
    "        newLast[:-lastBlock,:] = results[-1,0,lastBlock:,:]\n",
    "        results[-1,0,...] = newLast\n",
    "    preBlocks = torch.zeros((4,1,*DCfg.gapSh), device=TCfg.device)\n",
    "    pstBlocks = torch.zeros((4,1,*DCfg.gapSh), device=TCfg.device)\n",
    "    for curs in range(4) :\n",
    "        preBlocks[ -curs-1 , 0 , sinoCutStep*(curs+1) :  , : ] = results[ 0 , 0 , : -sinoCutStep*(curs+1) , : ]\n",
    "        pstBlocks[ curs , 0 , : (-sinoCutStep*curs) if curs else (blockH+1) , : ] = results[ -1 , 0 , sinoCutStep*curs : , : ]\n",
    "    resultsPatched = torch.cat( (preBlocks, results, pstBlocks), dim=0 )\n",
    "\n",
    "    blockCut = blockH / 5\n",
    "    profileWeight = torch.empty( (blockH,), device=TCfg.device )\n",
    "    for curi in range(blockH) :\n",
    "        if curi < blockCut :\n",
    "            profileWeight[curi] = 0\n",
    "        elif curi < 2 * blockCut :\n",
    "            profileWeight[curi] = ( curi - blockCut ) / blockCut\n",
    "        elif curi < 3 * blockCut :\n",
    "            profileWeight[curi] = 1\n",
    "        elif curi < 4 * blockCut :\n",
    "            profileWeight[curi] = ( 4*blockCut - curi ) / blockCut\n",
    "        else :\n",
    "            profileWeight[curi] = 0\n",
    "    #plotData(profileWeight.numpy())\n",
    "    resultsProfiled = ( resultsPatched + 0.5 ) * profileWeight.view(1,1,-1,1)\n",
    "    stitchedGap = torch.zeros( ( (resultsProfiled.shape[0]-1) * sinoCutStep + blockH, DCfg.gapW ), device=TCfg.device )\n",
    "    for curblock in range(resultsProfiled.shape[0]) :\n",
    "        stitchedGap[ curblock*sinoCutStep : curblock*sinoCutStep + blockH , : ] += resultsProfiled[curblock,0,...]\n",
    "    stitchedGap = stitchedGap.unsqueeze(0).unsqueeze(0)\n",
    "    resizedGap = torch.nn.functional.interpolate(\n",
    "        stitchedGap, size=( stitchedGap.shape[-2] ,  blockW), mode='bilinear')\n",
    "\n",
    "    sinogram[..., 2*blockW : 3*blockW ] = resizedGap[0,0, sinoCutStep*4 : sinoCutStep*4 + sinoL, : ] / 2\n",
    "    return sinogram\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Test</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inSinogram = torch.tensor(inData[:,300,605:665], device=TCfg.device)\n",
    "#print(inSinogram.shape)\n",
    "#\n",
    "#filledSinogram = fillSinogram(inSinogram).squeeze()\n",
    "#tifffile.imwrite(\"tmp.tif\", filledSinogram.cpu().numpy())\n",
    "#plotImage(filledSinogram.transpose(0,1).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Execute</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/934 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 934/934 [09:57<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#inputString = \"/home/imbl/usr/src/bctppl/data/clean_org_0005_2650_AM.hdf:/data\"\n",
    "inputString = \"/home/imbl/usr/src/bctppl/data/clean_sft_2701_5346_AM.hdf:/data\"\n",
    "gapsToProc = [\n",
    "    np.s_[113:117],\n",
    "    np.s_[629:641],\n",
    "    np.s_[1153:1157],\n",
    "    np.s_[1669:1681],\n",
    "    np.s_[2193:2197],\n",
    "]\n",
    "inData = getInData(inputString)\n",
    "outputString = \"/home/imbl/usr/src/bctppl/data/result.hdf:/data\"\n",
    "\n",
    "outData, outFile = getOutData(outputString, inData.shape)\n",
    "try :\n",
    "    for curSl in tqdm.tqdm(range(inData.shape[-2])):\n",
    "        inSinogram = torch.tensor(inData[:,curSl,:], device=TCfg.device)\n",
    "        for gap in gapsToProc :\n",
    "            gapW = gap.stop-gap.start\n",
    "            stripe=np.s_[ gap.start - 2*gapW : gap.stop + 2*gapW]\n",
    "            stripeData = inSinogram[:,stripe]\n",
    "            filledData = fillSinogram(stripeData).squeeze()\n",
    "            inSinogram[:,stripe] = filledData\n",
    "        outData[:,curSl,:] = inSinogram.cpu().numpy()\n",
    "except :\n",
    "    outFile.close()\n",
    "    raise\n",
    "outFile.close()\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
